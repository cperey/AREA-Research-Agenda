,Title,Description,Keywords,Categories,Stakeholders,Importance,Methodologies,Timeframes,Program,Miscellaneous,Author,History,Score,Relevant Publications
0,Visualization of Data About or From Tools in AR Display,"Combining live sensor data and tools with AR displays enables many use cases. This topic studies how to meet requirements of Industrial Internet of Things (IIoT) use cases in new and intuitive ways. In the IIoT, and as part of Industry 4.0, machines and tools run software and may be connected to corporate infrastructure with cables or radios. Frequently, there are consoles on which a user receives tool status and diagnostics. Sensors may be integrated or attached to a tool, thereby enhancing the tool's capability. A tool without direct connection to enterprise IT may be detected with the AR system or paired with a user's AR device. Data from tools (or from a technician's AR system) may be sent to work order management systems, SCADA, and asset tracing and tool use or management systems (e.g., the torque on a screw needs to be increased or decreased).

When an AR-assisted user is controlling connected tools (or interacting with unconnected tools) to perform a task, they do not need to turn their attention away from the main task to receive useful information. However, it is critical that the information provided in AR does not interfere with the user's awareness of the tool and is of value to the user. There is the potential for back-end IIoT systems to contribute to the user's productivity by providing clear indicators of status.

This research topic explores and studies the usability of different approaches to visualize data from or about tools (that may be generated by a user's own device) in an IIoT context. The research could also include making, with AR device pairing, those tools without sensors or that are not connected, more detectable and/or intelligent. The user may also have the ability to receive and to see in their AR display assistance from a remote tool or system expert. The research can also examine integration of data from tools and users' devices with operational software to automatically track processes, apply quality control, and access recommendations for users and managers.

","connected tools, manufacturing, AR display, industrial Internet of Things (IIoT), SCADA, asset tracing, asset management, maintenance, diagnostics, usability, perception, real time sensor data, tools, Internet 4.0, smart tools, sensors, remote assistance, work instructions, interactive systems and tools, Internet of Things, sensors, manufacturing","Business, Technology, Use Cases, Industries","Operators of manufacturing, repair, maintenance facilities, quality managers, managers of factories, providers of repair and maintenance services, oil and gas, power and energy, medical practitioners, experience designers, enterprise IT, systems integrators specializing in IIoT or Industry 4.0","- AREA members with manufacturing facilities for assembly, or providing repair or maintenance services, or field services where complex, connected (or not ""smart"") tools are used need better ways to visualize data and to provide instantaneous status information to users.
- By immediately visualizing feedback about the status of a tool or process, the user will save time and perform the task or process to criteria the first time. However, the additional information provided must not interfere with performance of tasks and must be compliant with regulations.
- Assessment of technician sentiment toward the AR-connected tools (i.e. do experienced technicians feel they would need this and/or does it affect existing workflow?) could lead to improvements in design or introduction of AR.
- Increased understanding of operational improvements tied to connected tools could improve cost savings analysis and RoI calculations.","An experimental environment using a range of connected or smart tools and procedures will provide the suitable environment for this research. Users of Industrial Internet of Things (IIoT) or Industry 4.0 systems will perform tasks under controlled conditions. Motion and time studies, quality inspection and other measurements of performance will be used to quantify impacts. Users will complete surveys about satisfaction and feedback on various visualizations.",Medium,"This research topic is broad in scope. It can include exploring different approaches to visualize data about tools to better understand and document or compare usability. This would benefit the industry by establishing Industry 4.0 best practices or guidelines. The research could also include making, with AR device pairing, those tools without sensors or that are not connected, more detectable and/or intelligent. This would expand the types and number of existing tools that would be tracked, without the cost of replacing tools that were developed prior to Industry 4.0 adoption. It also can examine integration of data from tools and users' devices with operational software to automatically track processes and provide remote assistance, quality control and recommendations for users and managers. Further, this topic can be combined with studies of AR-enabled guidance, integration of AR with IoT, finding parts and supplies in a large space with AR, 3D user interfaces, live sensor visualization for other use cases, and other use cases in factory or field settings.","Two AREA members with financial support from both industry and government [MxD (in US), the Manufacturing Technology Center (MTC), and the AMRC (in UK)] have the required experimental environments and have already begun studying the approaches in this topic.

In December 2014, there was on https://www.plex.com/[the Plex web site] a blog post about the specific use case of a https://www.plex.com/blog/internet-making-things-connected-torque-wrench[connected torque wrench].",Christine Perey,8/31/2021,3.74,"Norman, M., Lee, G., Smith, R. T., & Billinqhurs, M. (2019). A Mixed Presence Collaborative Mixed Reality System. 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2019.8797966 | Cavallo, M., & Forbes, A. G. (2019). CAVE-AR: A VR Authoring System to Interactively Design, Simulate, and Debug Multi-user AR Experiences. 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2019.8798148 | Hoffmann, C., Büttner, S., Prilla, M., & Wundram, K. (2020). Impact of augmented reality guidance for car repairs on novice users of AR. Proceedings of the Conference on Mensch Und Computer. URL: https://doi.org/10.1145/3404983.3405594 | Chen, Z., Su, Y., Wang, Y., Wang, Q., Qu, H., & Wu, Y. (2020). MARVisT: Authoring Glyph-Based Visualization in Mobile Augmented Reality. IEEE Transactions on Visualization and Computer Graphics, 26(8), 2645-2658. URL: https://doi.org/10.1109/tvcg.2019.2892415 | Nebeling, M., & Speicher, M. (2018). The Trouble with Augmented Reality/Virtual Reality Authoring Tools. 2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2018.00098"
1,AR for Material Management and/or Supply Chain Flow with Work Orders,"Many industries track supply chains and juggle limited supplies of components, ingredients, or materials while planning work orders in a system. Combining data with AR displays could provide up-to-date information to users while on the job and assist in distributing human resources according to availability of materials. In the Industrial Internet of Things (IIoT), a facility or job site that is nearing the end of materials or has just received a shipment of materials can bring this status information into the AR-assisted user's field of view with updated work orders, reducing delays and optimizing use of resources and distribution of workers.

This topic explores how to better share information about materials, equipment, and tools tracked in operations management software, and, when there are mission critical updates, how to display to a user current information about materials. The user may receive a new work order, be warned about material shortages, or be notified of a new assignment to move materials between locations, for instance. In the latter use case, the user may receive AR-assisted navigation support.

When an AR-assisted user is made aware of status of materials in the supply chain, they are prepared to adapt and feel more satisfied. In addition, there is the potential for back-end IIoT systems to track the user's location before sending instructions with respect to material availabilities.

This research topic explores different approaches to communicating and visualizing levels of materials in an IIoT context to study usability and impacts on worker productivity and satisfaction. It also examines integration of data from connected pallets and packaging and users' devices with operational software to automatically track processes, check in/check out, and make recommendations for users and managers.

","logistics data processing, materials management, supply chain management, logistics, asset tracing, asset tracking, asset management, Industrial Internet of Things (IIoT), usability, perception, work orders, productivity, navigation, interactive systems and tools, Internet of Things, supply chain, time difference of arrival, warehouse automation, logistics data processing, pallets, supply chain management, manufacturing, mapping","Business, Technology, Use Cases, End User and User Experience","operators of manufacturing, repair, employees and technicians in manufacturing facilities or on sites where parts and materials are distributed, maintenance managers, quality managers, managers of factories, providers of repair and maintenance services, supply chain managers","- AREA members with manufacturing facilities for assembly, those providing repair or maintenance services, and those providing field services where materials must be combined with a worker's skills and availabilities need better ways to visualize data in situ and predict and plan work accordingly.
- Traditional ERP solutions for supply chain and work order management do not alert users to status updates in their visual field, so while they may provide real-time information, the technician must get information from other sources to act upon the change in status.
- AR systems connected to data processing for parts and supplies on a work site could provide instantaneous status information and guidance, and even navigation, to users.
- By immediately visualizing where materials are to be found and whether they are limited, the system will allow the user to waste less time waiting for materials and allow them to move parts or supplies to their optimal positions.","An experimental environment using a range of manufacturing conditions, materials, and procedures is the suitable environment for this research. Users of any tools or assembly systems located in facilities with limited ability to store local components will perform tasks under controlled conditions. Alerts will be introduced when supplies are nearly exhausted and when new shipments or orders arrive, along with other relevant real time information. Motion and time studies, quality inspection, and other measurements of performance will be used to quantify impacts. Users will complete surveys about satisfaction and feedback on various visualizations.",Medium,"This research topic can be combined with studies of AR-enabled guidance, 3D user interfaces, live sensor visualization for other use cases in factory and field settings, visualization of connected objects (e.g., tools), and IoT data streams.","Three non-commercial AREA members with financial support from both industry and government [MxD (in US), the Manufacturing Technology Center (The MTC, in UK) and the Advanced Manufacturing Research Center with Boeing (AMRC in UK)] have the required experimental environments and have already begun studying the approaches in this topic.",Christine Perey,8/31/2021,2.64,"Kocisko, M., Teliskova, M., Baron, P., & Zajac, J. (2017). An integrated working environment using advanced augmented reality techniques. 2017 4th International Conference on Industrial Engineering and Applications (ICIEA). URL: https://doi.org/10.1109/iea.2017.7939222 | Han, Y., Lee, C., Kim, S., & Ko, S. (2019). System Architecture for Progressive Augmented Reality (poster). Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. URL: https://doi.org/10.1145/3307334.3328605 | De S Ribeiro, M. G., Mazuecos, I. L., Marinho, F., & dos Santos, A. N. G. (2019). Agile Explorations in AR. IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society. URL: https://doi.org/10.1109/iecon.2019.8926838 | Haque, R., Islam, M. M., Salma, S., Al Jubair, M. A., & Weng, N. G. (2020). Extracting Relevant Information Using Handheld Augmented Reality. Proceedings of the International Conference on Computing Advancements. URL: https://doi.org/10.1145/3377049.3377069 | Quandt, M., Beinke, T., & Freitag, M. (2020). User-Centered Evaluation of an Augmented Reality-based Assistance System for Maintenance. Procedia CIRP, 93, 921-926. URL: https://doi.org/10.1016/j.procir.2020.03.053"
2,Dynamic Distribution of Sensing and Processing Capacity via Body-Area Networks,"Deploying enterprise AR solutions via head-mounted displays is inherently advantageous when simultaneous use of both hands is required. However, currently HMD performance is limited due to technological constraints, such as battery life and heat dissipation needs. One solution is to offload and distribute sensing and processing functions dynamically across other devices worn by the user (smartwatches, exoskeletons, sensing devices etc.)--that is, to a network of external wearable devices and resources.

A network of computing and sensing resources would not only decrease the display processing requirements, it would also enrich data feeds available in a complete AR system. A distributed architecture composed of haptic inputs, auditory signals, vibration and other sensors could provide richer data about the wearer (e.g. pose/posture of different body parts) and the environment. For example, using more diverse sensors could increase the system's ability to detect safety risks before they are clear to the user.

The inputs from more and more varied sensors should be studied for new opportunities. Power savings and a less-heavy headworn display are clear benefits, but the architecture presents many challenges. Having multiple, distributed sources of input or computational functions will require integrating, in real time, separate data streams into a cohesive model. In addition to the user's personal body-worn network, the merging and integration of computational functions could be performed on the edge or in the cloud, leveraging 5G in some cases.

This topic will include in its scope defining and testing different approaches to distributed sensors on the user's body and distributing processing capacity and assessing their impacts if any on device safety, weight, size, power consumption and cost, as well as calculating the utility/benefit ratio of different architectures.

","distributed computing architecture, body-worn mesh networks, body area network, sensor configuration, sensor control, head-mounted display device, wearables, cloud computing, sensor fusion, optimization, body area networks, off-display sensors, off-display processing, body sensor networks, personal area networks, mobile cloud computing, distributed computing, body area networks, wireless sensor networks, sensor fusion","Displays, Standards, Business, Technology","HMD manufacturers, AR display device designers, sensor developers, body area network manufacturers, OEM manufacturers, integrated solution and software developers",#NAME?,"Studies of wearable sensors, low-latency body area network technologies, and sensor fusion processors and their synchronization will be necessary to examine all aspects of this research topic. A research platform composed of configurable head-mounted AR display components could be designed. Sensor data tracing systems may need to be tested or developed to provide a complete understanding of architectural choices.",Long,"This topic is at the intersection of multiple domains including but not limited to sensor configuration and control, sensor registrations, data filtering, sensor fusion, user context capture, and body area networks. The result could contribute to design of new HMD architectures, high-performance, and network-based resources and services (eg., 5G).","Studies of optical and IMU sensor fusion for AR HMDs date have been published as early as 2003. A https://www.researchgate.net/publication/281764749_An_Inertial_and_Optical_Sensor_Fusion_Approach_for_Six_Degree-of-Freedom_Pose_Estimation[recent publication on the topic] of 6DOF pose proves that the approach is very reliable.

The https://illixr.org/[ILLIXR Consortium] is developing a platform which, if extended to include body area networks, could be appropriate for experimentation with different architectures.","Peter Orban, Christine Perey",8/31/2021,2.17,"Koutitas, G., Jabez, J., Grohman, C., Radhakrishna, C., Siddaraju, V., & Jadon, S. (2018). Demo/poster abstract: XReality research lab - Augmented reality meets Internet of Things. IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). URL: https://doi.org/10.1109/infcomw.2018.8406848 | Sosin, A., & Itoh, Y. (2019). WARP: Contributional Tracking Architecture Towards a Worldwide Augmented Reality Platform. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00032 | Hoang, T. N., Ferdous, H. S., Vetere, F., & Reinoso, M. (2018). Body as a Canvas. Proceedings of the 2018 Designing Interactive Systems Conference. URL: https://doi.org/10.1145/3196709.3196724 | Michael, M., Llorca, J., & Tulino, A. (2019). Approximation Algorithms for the Optimal Distribution of Real-Time Stream-Processing Services. ICC 2019 - 2019 IEEE International Conference on Communications (ICC). URL: https://doi.org/10.1109/icc.2019.8761192 | Cziva, R., & Pezaros, D. P. (2017). On the Latency Benefits of Edge NFV. 2017 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS). URL: https://doi.org/10.1109/ancs.2017.23"
3,Wearable vs Handheld vs Projection: Methods for Quantifying the Impact of AR Modality,"Tablets, mobile phones, and other handheld devices have been widely deployed in enterprise, including among frontline workers who use these devices to access contextually-relevant information while executing work procedures. Although hugely useful, their interaction paradigm forces workers to choose between carrying out the actual steps of a work procedure or interacting with the device. The choices the user makes can also present safety risks.

Commercially available wearable (head-mounted) displays enable frontline workers to consume context-relevant information while executing work procedures using both hands thereby Ã¢ÂÂ theoretically Ã¢ÂÂ speeding up work. The same could be true for projection-based AR approaches. And both approaches may decrease or completely mitigate safety risks innate to handheld devices. However, there is no independent assessment of the potential economic or safety benefits of the emerging, AR-enriched hands-free modalities.

This research topic focuses on the development of methodologies for performing objective, quantitative assessments of the impact of wearable and projection-based AR approaches compared to work procedures assisted by AR delivered using handheld devices. Measurement methods would be developed to ensure accuracy with a 95% confidence interval. The assessment methodology could include user acceptance of different modalities.

The research scope could be expanded to include performing comparative studies measuring the exact impact of wearable or projection AR modality vs. the handheld baseline across industries, use cases, and horizontal use case categories.

","efficiency, handheld, projection AR, wearable displays, head-mounted displays, usability, user perception, human factors, head worn displays, wearable computers,","Displays, Business","Operations leaders, financial management, OEM manufacturers, Independent Software Vendors,","- Wearable AR displays provide frontline workers in AREA member companies with information without requiring the user to hold a display in their hands or look away from their tasks while obtaining instructions.
- However, deploying display devices with entirely different form factors than those widely adopted, developing and deploying appropriate software, and integrating and training users on the new devices introduces time and expenses Ã¢ÂÂ particularly if handheld displays have been well-integrated in the current procedures.
- The AREA members need ways to measure and/or to calculate the investments and benefits of using different form factors in the workplace.","The research will contribute to development of tools to accurately, impartially measure the differences between handheld and wearable displays. The measurement methods will be used on groups of users sufficiently large in number and diverse in profile to allow projection across various attributes (e.g. time saved, quality improved, error eliminated, etc.). The research tools can include time-motion studies using standardized, public, well-documented processes typical of industry verticals, use cases, and horizontal use case categories.",Near,"This research can be combined with or extended to include different wearable form factors, including but not limited to monocular displays and binocular or holographic displays. The research scope may also be expanded to apply the same methods to study the return on investment of emerging use cases and AR in industries that have not been well documented.",The AREA RoI calculator is a starting point for quantifying the economic impacts of AR in repair and maintenance use cases. This research topic could contribute to the expansion of the AREA RoI calculator.,"Peter Orban, Christine Perey",8/31/2021,2.98,"Goh, E. S., Sunar, M. S., & Ismail, A. W. (2019). 3D Object Manipulation Techniques in Handheld Mobile Augmented Reality Interface: A Review. IEEE Access, 7, 40581-40601. URL: https://doi.org/10.1109/access.2019.2906394 | Fadzli, F. E., Yusof, M. A. M., Ismail, A. W., Salam, M. S. H., & Ismail, N. A. (2020). ARGarden: 3D outdoor landscape design using handheld augmented reality with multi-user interaction. IOP Conference Series: Materials Science and Engineering, 979, 012001. URL: https://doi.org/10.1088/1757-899x/979/1/012001 | Müller, J., Zagermann, J., Wieland, J., Pfeil, U., & Reiterer, H. (2019). A Qualitative Comparison Between Augmented and Virtual Reality Collaboration with Handheld Devices. Proceedings of Mensch Und Computer 2019. URL: https://doi.org/10.1145/3340764.3340773 | Heinrich, F., Schwenderling, L., Joeres, F., Lawonn, K., & Hansen, C. (2020). Comparison of Augmented Reality Display Techniques to Support Medical Needle Insertion. IEEE Transactions on Visualization and Computer Graphics, 26(12), 3568-3575. URL: https://doi.org/10.1109/tvcg.2020.3023637 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089"
4,Impact of AR Delivery on People Living in Multidimensional Poverty,"The Multidimensional Poverty Index (MPI) ""measures the complexities of poor people's lives, individually and collectively, each year."" The measure was co-developed between the Oxford Poverty and Human Development Initiative at the University of Oxford and the Human Development Report Office of the United Nations Development Programme in 2010. It is a key measure for developing countries with regards to progress toward eliminating world poverty. Importantly, this specific measure accounts for many elements of non-monetary poverty to calculate an overall score, composed of three dimensions: health, education, and standard of living. According to the 2020 report ""Charting pathways out of multidimensional poverty: achieving the SDGs,"" ""this is a key moment to study how nonmonetary poverty goes down. It is 10 years before 2030, the due date of the Sustainable Development Goals (SDGs), whose first goal is to end poverty in all its forms everywhere. And it is a year when a pandemic and economic slowdown are pushing many more into poverty, while the spectre of racism still haunts, and environmental threats such as locusts surge.""

Because AR is a unique information delivery format that is highly conducive to providing increased accessibility to skill acquisition, learning, and even remote healthcare, and given the challenges that COVID has brought into the mix in 2020, UN nations will increasingly be looking for ways to sustain growth and minimize regression with regards to 2030 UN SDG targets. Because education accounts for 1/3 of the Multi-dimensional Poverty Index and this index is measured annually and can be applied flexibly to individuals, this is an ideal opportunity in time to investigate the impacts of AR with regards to reducing world poverty. There is likely to be substantial interest within local governments as well as amongst corporate entities supporting the UN 2030 SDGs.

This research topic focuses on measuring how access to AR systems for delivery of educational and healthcare programs over the course of a year impacts individual MPI. It will involve engagement with at-risk communities and require a combination of social and technological measurement tools.

","United Nations, Sustainable Development Goals (SDG), Multidimensional Poverty Index (MPI), poverty, policy, education, skill development, socio-economic effects, social aspects, social and economic effects, subjective testing, behavioral research","Business, End User and User Experience","Government officials and policymakers in World Bank Group and UN nations, social performance/impact executives in large, global organizations, particularly those with a large social license to operate - preference to industries in which corporations provide educational and healthcare services for many aspects of community life (e.g. metals and mining), education policy makers/professionals.","- Because AR is a unique delivery format that is highly conducive to providing increased accessibility to skill acquisition, learning, and even remote healthcare, and given the challenges that COVID has brought into the mix in 2020, UN nations will increasingly be looking to ways to sustain growth/minimize regression with regards to 2030 UN SDG targets.
- Because education accounts for 1/3 of the Multi-dimensional Poverty Index and this index is measured annually and can be applied flexibly to individuals, this is an ideal opportunity in time to investigate the impacts of AR with regards to reducing world poverty.
- There is likely to be substantial interest within local governments as well as amongst corporate entities supporting the UN 2030 Sustainable Development Goals.","The proposed research would need to decide upon a flexible scoring mechanism for individual MPI (see https://mppn.org/multidimensional-poverty/how-is-calculated/[multidimensional poverty calculation]).

The principal investigator would develop partnerships with a host corporation and community. Research would include calculation of pre-study MPIs and introduction of AR intervention via A/B trial scenarios, potentially with a few different levels of AR intervention. Then researchers would collect data about post-intervention behaviors and worker status.

Post-study MPIs could be calculated and recommendations developed for future implementation.
",Near,"This study could link closely with existing research programs associated with metals and mining, education, and policy, as well as potentially healthcare, depending upon the scope of the research project.","The Multidimensional Poverty Index (MPI) ""measures the complexities of poor people's lives, individually and collectively, each year."" The measure was co-developed between the Oxford Poverty and Human Development Initiative at the University of Oxford and the Human Development Report Office of the United Nations Development Programme in 2010. It is a key measure for developing countries with regards to progress toward eliminating world poverty. Importantly, this specific measure accounts for many elements of non-monetary poverty to calculate an overall score, comprised of three dimensions: health, education, and standard of living. According to the 2020 report ""Charting pathways out of multidimensional poverty: achieving the SDGs,"" ""this is a key moment to study how non-monetary poverty goes down. It is 10 years before 2030, the due date of the Sustainable Development Goals (SDGs), whose first goal is to end poverty in all its forms everywhere. And it is a year when a pandemic and economic slowdown are pushing many more into poverty, while the spectre of racism still haunts, and environmental threats such as locusts surge.""

References related to risk appetite matrices:
http://hdr.undp.org/sites/default/files/2020_mpi_report_en.pdf +
https://mppn.org/multidimensional-poverty/how-is-calculated/ +",Jennifer Rogers,8/31/2021,0.52,"Al Akil, D., Ahmed, V., & Saboor, S. (2020). The Utilization of Augmented Reality Technologies within the Engineering Curricula - Opportunities and Challenges. 2020 IFEES World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC). URL: https://doi.org/10.1109/weef-gedc49885.2020.9293626 | Mubeen, T., Hussain, S. K., & Aqeel, F. (2019). TALEM(The Advanced Learning and Education Management) System With OBE(Outcome-based Education). 2019 International Conference on Information Science and Communication Technology (ICISCT). URL: https://doi.org/10.1109/cisct.2019.8777424 | Blattgerste, J., Renner, P., & Pfeiffer, T. (2019). Augmented reality action assistance and learning for cognitively impaired people. Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments. URL: https://doi.org/10.1145/3316782.3316789 | Ahmad, N. I. N., & Junaini, S. N. (2020). Augmented Reality for Learning Mathematics: A Systematic Literature Review. International Journal of Emerging Technologies in Learning (iJET), 15(16), 106. URL: https://doi.org/10.3991/ijet.v15i16.14961 | Khowaja, K., Banire, B., Al-Thani, D., Sqalli, M. T., Aqle, A., Shah, A., & Salim, S. S. (2020). Augmented Reality for Learning of Children and Adolescents With Autism Spectrum Disorder (ASD): A Systematic Review. IEEE Access, 8, 78779-78807. URL: https://doi.org/10.1109/access.2020.2986608"
5,Passthrough vs. See-through: Impacts of Display Technology on Peripheral Vision,"Head-mounted AR displays (HMD) blend simulated reality with the real world while the user uses both hands. Some displays employ a Ã¢ÂÂvideo passthrough' approach (e.g. Oculus Quest), where image processing and graphics rendering blend and display physical and generated reality in real time -- an approach that is used in all handheld AR display systems. Due to technology limitations, video passthrough wearable devices provide a field of view (FoV) between 90 and 120 degrees, thereby limiting the user's peripheral vision.

As peripheral vision is important for user safety, maintaining partial or full peripheral vision is required in many situations. Wearable AR display devices based on optical see-through technology have far lower impact a user's physical world FoV (i.e., they do not interfere with the user's peripheral vision), however, the FoV in which the user perceives digital assets varies.

This research topic focuses on determining the minimum FoV required for wearable video see-through AR display devices to meet workplace safety requirements. The result will provide HMD designers guidance with respect to the minimum FoV (possibly foveated) that must be supported in video see-through in order to provide user experience comparable to the best-in-class optical see-through AR displays.

","video see-through, video passthrough, field of view, waveguide, birdbath, off-axis, light field, foveated rendering, human eye resolution, head-up displays, three-dimensional displays, micro displays, computer displays, liquid crystal displays, display devices, led displays, screens (display), color displays","Displays, Technology, End User and User Experience","Operations leaders, HMD designers, Safety & IT managers, OEM manufacturers, ISVs","- Most of the leading AR display component and system manufacturers are AREA members.
- Video passthrough displays using existing technologies for graphics overlay on video are less expensive to develop than optical see-through displays.
- AREA members would benefit from having objectively defined measures of the impact of head-worn video see-through displays on the user's peripheral vision.","Studies of human peripheral vision requirements and sensitivities to FoV constraints will need to be performed in highly controlled research conditions. A research platform composed of configurable head-mounted AR display components could be designed. The video passthrough experiences designed for the study will need to have the same level of latency as an optical see-through display and their weight and other ergonomic factors would need to be identical in order to study only the impact of the technology on user's vision. Eye-tracking data could be used to measure the user's gaze and extensive user interviews or other measurement systems would be needed to capture the impacts of the options on eye fatigue, cognition, and task performance.",Near,This research can be combined with or extended to include different wearable form factors including but not limited to monocular displays and binocular or holographic displays. The research scope may also be expanded to apply the same methods to study user safety and comfort. It is also highly valuable to explore how the video and optical see-through displays differ in producing highly registered AR experiences and permitting other optical features.,"Although quite dated by today's stamdards, one of the https://www.researchgate.net/profile/Jannick-Rolland/publication/220089776_Optical_Versus_Video_See-Through_Head-Mounted_Displays_in_Medical_Visualization/links/0fcfd50f59745391b5000000/Optical-Versus-Video-See-Through-Head-Mounted-Displays-in-Medical-Visualization.pdf[first studies focusing on this topic] was performed by Dr. Jannick Rolland and Dr. Henry Fuchs to examine the pros and cons of these two display options in a surgical use case. The study was published in the journal ""Presence"" in 2000.

The topic of mitigating parallax-related registration errors is a highly active field of study, as demonstrated by
https://www.frontiersin.org/articles/10.3389/frobt.2020.572001/full[this article published in December 2020] in the Frontiers in Robotics and AI journal.","Peter Orban, Christine Perey",8/31/2021,3.22,"Iwai, D., Itoh, Y., & Punpongsanon, P. (2018). Computational Augmented Reality Displays. Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces. URL: https://doi.org/10.1145/3279778.3279808 | Surman, P., Zhang, X., Song, W., Xia, X., Wang, S., & Zheng, Y. (2020). Glasses-Free 3-D and Augmented Reality Display Advances: From Theory to Implementation. IEEE MultiMedia, 27(1), 17-26. URL: https://doi.org/10.1109/mmul.2019.2948334 | Spjut, J., Boudaoud, B., Kim, J., Greer, T., Albert, R., Stengel, M., ... Luebke, D. (2020). Toward Standardized Classification of Foveated Displays. IEEE Transactions on Visualization and Computer Graphics, 26(5), 2126-2134. URL: https://doi.org/10.1109/tvcg.2020.2973053 | Otao, K., Itoh, Y., Osone, H., Takazawa, K., Kataoka, S., & Ochiai, Y. (2017). Light field blender. SIGGRAPH Asia 2017 Technical Briefs. URL: https://doi.org/10.1145/3145749.3149425 | Wang, S., Liu, H., Shu, H., Zhang, X., & Zhang, Y. (2020). Design and Development of Campus Environment Display System Based on Augmented Reality Technology. IOP Conference Series: Materials Science and Engineering, 790, 012031. URL: https://doi.org/10.1088/1757-899x/790/1/012031"
6,New Power Sources for Wearable AR Displays,"As the complexity and computational requirements of world capture, world analysis, scene management, rendering, and human interactions with AR experiences increase, a delicate balance must be struck so as to ensure that the useful life of a device between recharges is not too low. Power management may be addressed through a combination of different approaches, including increase in use of low power DSPs, off-loading some computational tasks to the edge of the network (off-device services), and increasing power storage capacity. There is another potentially powerful resource to address the duration of wearable AR display usage. This topic focuses on the research and development of novel methods to capture power from the user or the environment that could be transferred to the power storage system.

Specifically, the proposed topic will research, build, and test implementations of new methods of energy harvesting from sources that have not been used in prior wearable AR display systems. There will need to be studies of human movement (steps, arms, hands), solar sources for users that are outdoors, and chemical reactions that release energy. This topic will span a wide range of technologies, including analysis of the power requirements of each individual AR display component.

","power use, power consumption, power production, AR device energy sources, energy capture, energy production, AR device energy transfer, energy consumption, energy management, electromechanical, solar energy, friction, power storage for AR displays, human factors, weight, usability, portability, computational efficiency, low power electronics, electric batteries, power consumption, power conversion, power aware computing","Displays, Technology","All users of wearable AR display devices and those who manage their use in the workplace will benefit from longer duration between recharges. Introducing or integrating novel power production, transfer, and storage technologies will have impacts on display costs, which could affect the number of devices purchased.","- Most of the leading AR display component and system manufacturers are AREA members.
- Use of wearable AR displays in AREA member settings is limited by many factors, one of which is the size and weight of the display needed in order to store sufficient energy to power the computational processing requirements of AR experiences.
- The issues of power storage to deliver energy for a full work shift can be addressed through reducing local (on-device) processing and power requirements, and increasing storage capacity.
- Having continuously generated power from a source such as the movements or environment of the user is an approach that has not received extensive study but could introduce an attractive alternative to removing a device from use for charging.","The research will be leveraging developments in physics, chemistry, and other sciences pertaining to energy production and combining those with deeper studies of wearable AR display device power use. In addition to theoretical calculations, there will need to be prototypes developed and tested to measure the efficacy and efficiencies of power capture, storage, and use with AR displays. Finally, the introduction of new energy production, transfer, and storage methods or systems will need to be carefully studied for their safety in the workplace.",Long,"This research topic could be studied in different environmental conditions, such as indoors, outdoors, and in different temperatures. In addition, there will need to be studies of different use cases in which some users are actively moving throughout a work shift. The results of this research would also be very valuable for non-enterprise users and display devices.","This field of research is in its infancy, but there are some promising developments such as the electrochemically driven mechanical device developed at MIT and https://www.nature.com/articles/ncomms10146[revealed in 2016 in Nature].

The following articles, published in 2019 describe https://techxplore.com/news/2019-11-harvesting-energy-human-body.html[energy harvesting based on human body movement]; similar studies have been https://www.sciencedaily.com/releases/2019/07/190717122600.htm[reported here.]

This study of https://res.mdpi.com/d_attachment/energies/energies-13-03871/article_deploy/energies-13-03871-v2.pdf[measurement of the power produced] was published in 2020.",Christine Perey,8/31/2021,2.45,"Malhotra, N., Mann, A., & Pandey, N. (2019). Design of Low Power ECRL Based Power Gated 4:2 Compressor. 2019 6th International Conference on Signal Processing and Integrated Networks (SPIN). URL: https://doi.org/10.1109/spin.2019.8711712 | Ro, H., Park, Y. J., Byun, J.-H., & Han, T.-D. (2019). Mobile device interaction using projector metaphor. Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion. URL: https://doi.org/10.1145/3308557.3308672 | Alavikia, Z., & Shabro, M. (2019). Pragmatic Industrial Augmented Reality in Electric Power Industry. 2019 International Power System Conference (PSC). URL: https://doi.org/10.1109/psc49016.2019.9081538 | Sanches, S. R. R., Oizumi, M., Oliveira, C., Damasceno, E. F., & Sementille, A. C. (2017). Aspects of User Profiles That Can Improve Mobile Augmented Reality Usage. 2017 19th Symposium on Virtual and Augmented Reality (SVR). URL: https://doi.org/10.1109/svr.2017.38 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089"
7,Low Power Digital Signal Processors for Use in AR Display Devices,"While the data about the user's context is captured, fused, and filtered in one digital signal processor (DSP), vision processing units (VPUs) are analyzing individual and fused data signals to detect key features (e.g., objects) of the real world. Audio processing also requires computing resources. At the precise moment when AR experiences are delivered to users, power is needed for the rendering computations. This power usage must not compete with the power necessary for the optics, auditory, or other real time processes to produce digital assets visible to the user.

DSPs are common components of AR Systems-on-Chips (SoCs) in displays. The DSPs accelerate the classes of computational tasks required for optimal performance of AR systems. They can be configured and optimized to specific parameters, matching the sensors that capture the real world tasks that they perform and even the use case or user's requirements.

To reduce total display power usage and increase the time between charges, fundamental research needs to advance the state of the art in design and production of low-power DSPs dedicated to every computationally intensive component of enterprise AR displays and delivery systems.

This research needs to be performed without interference with existing patents and be published and available to component manufacturers and AR display manufacturers without license or fees in order to accelerate the development of new DSPs and to reduce the cost of high-performance enterprise AR display devices and other mobile hardware.

","Low power, power use, power consumption, digital signal processing, DSP, VPU, SoC, AR display hardware, digital signal processing, low power electronics, heads-up displays, power consumption","Displays, Technology","AR display designers, AR display manufacturers, original equipment manufacturers (OEM) of semiconductors for AR displays, AR systems integrators",#NAME?,"Semiconductor and DSP designers can collaborate with other AR ecosystem segments to increase their understanding of the diversity of real world requirements. Using machine learning and artificial intelligence, designers will optimize new DSP architectures for AR-specific functions.",Long,This research can be combined with fresh research approaches to create new power capture and power storage technologies for use in AR display designs.,"A 2018 https://www.qualcomm.com/media/documents/files/the-mobile-future-of-augmented-reality.pdf[Qualcomm Technologies presentation] describes important computing tasks and functions of signal processors in advanced AR display devices.

This is a https://community.arm.com/innovation/b/blog/posts/maximizing-the-system-efficiency-of-augmented-reality-devices[blog post] published June 2020 on the ARM community web site about this research topic.",Christine Perey,8/31/2021,3.69,"Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089 | Malhotra, N., Mann, A., & Pandey, N. (2019). Design of Low Power ECRL Based Power Gated 4:2 Compressor. 2019 6th International Conference on Signal Processing and Integrated Networks (SPIN). URL: https://doi.org/10.1109/spin.2019.8711712 | Fadzli, F. E., Yusof, M. A. M., Ismail, A. W., Salam, M. S. H., & Ismail, N. A. (2020). ARGarden: 3D outdoor landscape design using handheld augmented reality with multi-user interaction. IOP Conference Series: Materials Science and Engineering, 979, 012001. URL: https://doi.org/10.1088/1757-899x/979/1/012001 | Iwai, D., Itoh, Y., & Punpongsanon, P. (2018). Computational Augmented Reality Displays. Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces. URL: https://doi.org/10.1145/3279778.3279808 | Schmalstieg, D. (2018). VIS Keynote Address : When Visualization Met Augmented Reality. 2018 IEEE Conference on Visual Analytics Science and Technology (VAST). URL: https://doi.org/10.1109/vast.2018.8802427"
8,AR Visualization of Body Sensors for Worker Biofeedback,"During the performance of tasks or fulfilment of roles, an employee may be unaware of changes in their involuntary bodily functions such as blood pressure and heart rate. When aware of any unusual metrics, the user can choose or be prompted to take appropriate actions. Visual and/or auditory information captured in real time by body-worn sensors (e.g., watches) could capture posture, head flexion and extension, whether the arms are above the shoulders, and possibly even squatting. The system could provide feedback on static posture duration and/or frequency and suggest postural changes or breaks based on criteria that increase the risk of muscular skeletal disorders.

The sensor data can be provided to the AR display through a body-area network. This topic focuses on the low-latency transmission and processing of observations from body-worn sensors to the user's AR display and the presentation of data and recommendations in a compact and actionable manner. The system design research should explore both automated modes (which are triggered upon the user's functions reaching a threshold) as well as manually controlled modes (e.g., enabled by a user seeking to obtain vital statistics). There must also be research to ensure that any AR visualization system is secure and upholds all relevant user data privacy protection policies.

","Biometrics, body sensors, blood pressure, heart rate, body temperature, body-area network, biofeedback, user data privacy protection, visualisation, alerts, biofeedback, biometrics, body area network","End User and User Experience, Technology","Companies monitor and manage workplaces for their suitability to employees. This research will be valuable to all workplace health and safety professionals, wellness specialists, human resources managers, user data privacy policy analysts, employees, and managers.","- Employees of AREA members may work in conditions that are highly stressful and/or require postures that introduce risk of injuries. Others must concentrate while working in environmental conditions that are known or anticipated to produce risks to employee well-being (e.g., around vibrations or loud machines). Body-worn sensors can detect abnormal behaviors in the workers' involuntary bodily functions, postures, and use of body parts.
- The implementation of body-worn sensors could be controversial if their ability to protect user data privacy is not clearly demonstrated.
- By using a body-area network and connecting it with their AR display, an employee will be able to see any anomalies in their real time and historical biometrics without distracting them from their task or releasing their personal data.
- With biometric information in their field of view, the AREA employee can modify their behaviors (e.g., reduce stress, change posture, or make other adjustments to manage their body's response to conditions in their workplace).","Research on this topic includes testing and studying the features of body-worn biometric devices in professional settings. It will be necessary to design and build a body-area network supporting existing standards in order to interface with radios and technologies on AR display devices. The research will also require designing and studying the usability, efficacy, and performance of AR-enriched user interfaces for providing a user with only pertinent biometric data via an AR display.",Medium,"This research topic can be combined with other topics pertaining to automated alerting of users to risk conditions using the AR display. It can also extend research on biometrics, biofeedback, and behavior modification therapies.","A peer-reviewed study of a biofeedback system combined with a VR display for managing emotional states was https://dl.acm.org/doi/abs/10.1145/3089269.3089273[published in SIGGRAPH '17 proceedings]. As documented in this https://res.mdpi.com/d_attachment/applsci/applsci-09-03248/article_deploy/applsci-09-03248.pdf[2019 review of the state of the art of body-area network usage in healthcare], the technology is maturing. Combining body-area networks and AR in professional domains is an unexplored field that has high potential for impact.

Similarly, biometrics and the use of biofeedback in the workplace are very large and active fields of research. However, to date, their intersection with Augmented Reality has not been documented in the peer-reviewed literature.",Christine Perey,8/31/2021,2.41,"Hoang, T. N., Ferdous, H. S., Vetere, F., & Reinoso, M. (2018). Body as a Canvas. Proceedings of the 2018 Designing Interactive Systems Conference. URL: https://doi.org/10.1145/3196709.3196724 | Pohl, H., Dalsgaard, T.-S., Krasniqi, V., & Hornbæk, K. (2020). Body LayARs: A Toolkit for Body-Based Augmented Reality. 26th ACM Symposium on Virtual Reality Software and Technology. URL: https://doi.org/10.1145/3385956.3418946 | Cao, Y., Qian, X., Wang, T., Lee, R., Huo, K., & Ramani, K. (2020). An Exploratory Study of Augmented Reality Presence for Tutoring Machine Tasks. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. URL: https://doi.org/10.1145/3313831.3376688 | Ueda, Y., Asai, Y., Enomoto, R., Wang, K., Iwai, D., & Sato, K. (2017). Body cyberization by spatial augmented reality for reaching unreachable world. Proceedings of the 8th Augmented Human International Conference. URL: https://doi.org/10.1145/3041164.3041188 | Koutitas, G., Jabez, J., Grohman, C., Radhakrishna, C., Siddaraju, V., & Jadon, S. (2018). Demo/poster abstract: XReality research lab - Augmented reality meets Internet of Things. IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). URL: https://doi.org/10.1109/infcomw.2018.8406848"
9,Development of Heuristics to Assess Enterprise AR Experience Design and Usability,"Usability heuristics are lists of design guidelines that developers and practitioners can use to evaluate the usability of applications in the design and development process. A heuristic evaluation is an activity conducted by a usability expert that involves a checklist of best practices. Applications are judged on their adherence to the checklist items, and the results are used to refine the application design so that it better meets the end user's needs.

While there are several general usability heuristics available for software interfaces (e.g., NielsenÃ¢ÂÂs 10 Usability Heuristics for User Interface Design, SchneidermanÃ¢ÂÂs Eight Golden Rules of Interface Design), there have been no heuristic checklists developed specifically to assess AR experiences for the workplace. Using a heuristic checklist targeted to enterprise AR reveals aspects beyond the general best practices that are unique to AR environments. This includes characteristics such as safety, comfort, user interaction methods, hardware setup and capabilities, and privacy.

This research topic involves the development of a new heuristic checklist for enterprise AR experience developers and practitioners to use to evaluate the usability of AR experiences and accompanying hardware.

","usability, user experience, heuristics, best practices, product design, software design, user centered design, design, hci design and evaluation methods","End User and User Experience, Industries, Technology","Developers, users, operators, users of AR applications","- This topic is of interest to AREA members because it helps to define best practices for AR application design.
- The outcomes of this effort will allow providers of enterprise platforms to more quickly and reliably assess usability and UX, which in turn will facilitate informed iterative design/development, resulting in more satisfying, efficient, and effective solutions.
- It is important to note that this checklist will complement user testing Ã¢ÂÂ it is not a replacement by any means.","QuiÃÂ±ones, Rusu, & Rusu (2018) outline a formal methodology for developing usability/user experience heuristics. The method has been applied in a number of domains outside of enterprise AR and validated by experts. This method involves a systematic literature review, examination of the experimental literature, detailed analyses of the characteristics heuristics should have in the domain, and three levels of validation.",Medium,This topic is academic in nature though the resulting heuristic checklist should be validated with many AREA stakeholders in a variety of domains and industries to ensure robustness and generalized usefuless among the wide range of AR applications used in enterprise settings.,"Details on how to develop a new set of heuristics for a domain are discussed in work by QuiÃÂ±ones, Rusu, & Rusu (2018) https://www.sciencedirect.com/science/article/pii/S0920548917303860?casa_token=9AqOOBdQFFQAAAAA:cIiacrm7bZ0rsL2UtTdLgQqgF1FnA6KZLknce5cphvYbiPh2fSZeNGoDXldyDpbspVWWD_4HnA/[in this article].",ERAU Team,8/31/2021,2.65,"Derby, J. L., & Chaparro, B. S. (2020). Use of Augmented Reality by Older Adults. Lecture Notes in Computer Science, 125-134. URL: https://doi.org/10.1007/978-3-030-50252-2_10 | Labrie, A., & Cheng, J. (2020, October). Adapting Usability Heuristics to the Context of Mobile Augmented Reality. In Adjunct Publication of the 33rd Annual ACM Symposium on User Interface Software and Technology (pp. 4-6). | Tuli, N., & Mantri, A. (2020). Usability Principles for Augmented Reality based Kindergarten Applications. Procedia Computer Science, 172, 679-687. URL: https://doi.org/10.1016/j.procs.2020.05.089 | Wiegand, G., Mai, C., Holländer, K., & Hussmann, H. (2019). InCarAR. Proceedings of the 11th International Conference on Automotive User Interfaces and Interactive Vehicular Applications. URL: https://doi.org/10.1145/3342197.3344539 | Masmuzidin, M. Z., & Aziz, N. A. (2019). The Adaptation of Shneiderman's Golden Rules and Nielsen's Heuristics on Motivational Augmented Reality Technology Design for Young Children. 2019 IEEE 9th International Conference on System Engineering and Technology (ICSET). URL: https://doi.org/10.1109/icsengt.2019.8906373"
10,Impact of Spatial Vision on Visual Encoding and Memory Anchoring,"Some complex instructions and illustrations used in training or on the job require greater time and cognitive load for workers to understand, retain, and use when displayed in planar mode (2D). Three-dimensional representations and spatial vision enabled by stereoscopy has been shown to increase comprehension of spatially relevant concepts and increases their encoding and retention in memory. Although technology today enables spatial vision, frequently it requires some level of compromise around performance, wearability, or resource requirements.

This research topic focuses on measuring the impact of binocular (vs monocular) vision on short- and long-term memory encoding (i.e., the process of changing sensory inputs into forms that are stored in the brain and anchored in such a way that enables effective retrieval).

","spatial vision, spatial memory, visual encoding, memory anchoring, spatial frequency, receptive Field, modulation transfer function, high spatial frequency, threshold contrast, spatial strategies, spatial orientation, object location, stereo image processing, image coding","Displays, Technology, End User and User Experience","user experience designers, AR experience developers, human resources professionals, AR display designers, AR display manufacturers, researchers studying cognition and performance of users in the workplace",#NAME?,"The research topic would need experts to develop and use a combination of existing neuro-analytical tools (tools that measure neurological brain activity) and biometric tools that infer neurological responses by proxy. The former includes EEG, fMRI (functional MRI), fNIRS (functional near-infared spectroscopy) and steady state topography (SST), all of which directly measure brain activity related to specific brain functions. For instance, SST measures the speed of electrical activity on the surface of the brain, linking changes in certain areas to specific metrics like engagement and memory encoding. The latter includes eye tracking, facial coding, and biometric data like heart rate monitoring. This research will analyze data for broader interpretation, offering insights into the use and impacts of 3D spatial viewing with AR, compared to measurements made by technology like SST and fMRI.",Near,This research topic can be integrated with fundamental research on brain function. It could also be combined with studies of specific use cases in which the system recalls the users' spatial vision strategies and enhances those selectively. User experience design would also benefit from studies of this and related neuro-analytical tools and topics.,"There has been research published on the topics of https://www.sciencedirect.com/topics/neuroscience/spatial-vision[spatial vision] and more specifically on AR and https://www.frontiersin.org/articles/10.3389/fnhum.2019.00113/full[memory encoding].

https://www.frontiersin.org/articles/10.3389/fnhum.2019.00113/full[This 2019 article published in Frontiers in Human Neuroscience] reports on research conducted using AR to assess the impact of gender on spatial vision and anxiety.","Peter Orban, Christine Perey",8/31/2021,1.74,"Yong, S., & Wang, H.-C. (2018). Using Spatialized Audio to Improve Human Spatial Knowledge Acquisition in Virtual Reality. Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion. URL: https://doi.org/10.1145/3180308.3180360 | Caluya, N. R., Plopski, A., Ty, J. F., Sandor, C., Taketomi, T., & Kato, H. (2018). Transferability of Spatial Maps: Augmented Versus Virtual Reality Training. 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2018.8447561 | Pangestu, A., & Setyaningrum, W. (2020). Instructional media for space geometry based on augmented reality to improve students' spatial reasoning. Journal of Physics: Conference Series, 1581, 012058. URL: https://doi.org/10.1088/1742-6596/1581/1/012058 | Vovk, A., Gasques Rodrigues, D., Wild, F., & Weibel, N. (2019). SIG. Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. URL: https://doi.org/10.1145/3290607.3311756 | Fuste, A., & Schmandt, C. (2019). HyperCubes: A Playful Introduction to Computational Thinking in Augmented Reality. Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts. URL: https://doi.org/10.1145/3341215.3356264"
11,Text Input with AR Head Mounted Displays,"Most AR experiences developed for mixed-reality head-mounted displays require some level of user interaction, such as text input, gestures, or voice input. While voice is the quickest method for a user to control and interact with digital assets, it is prone to error thanks to varying speaking styles, accents, and emotions. It is also not well suited to noisy industrial environments. Text input is typically conducted through hand or finger gestures or a handheld clicker with a virtual QWERTY keyboard. Research examining user performance reveals that both methods are cumbersome, with an average of 5-6 WPM. (For comparison, typical typing speeds on mobile devices range from 30 to 50 WPM.) This performance level is unacceptable for continued and effective use in the workplace. In addition, users may feel fatigued after holding their arm in compromising positions for extended periods of time.

User acceptance and satisfaction is critical and a common struggle among developers of alternate keyboard design, even outside of the HMD/AR domain. The QWERTY keyboard, for example, has been shown to result in slower performance than alternative designs, but the general public is unwilling to relearn a new method.

This research topic involves the study of alternate methods of text input to develop methods with higher performance and user satisfaction. The approaches to be studied include the design of a virtual keyboard and advancing the algorithms behind the keyboard predictive text functionality and user interaction (i.e., tap gesturing vs trace, eye gaze input).

","text entry, text editing, virtual keyboard, trace input, user experience, sensory perception, text analysis, gesture recognition, keyboards, speech-based user interfaces","End User and User Experience, Displays, Technology","Developers, operators of machinery, all users of AR experiences requiring user input of text, performance and quality control managers",#NAME?,"Researchers interested in this topic may examine the efficacy of the virtual keyboard design itself, the method of user interaction (speech, gesture type), or the predictive text algorithms used. A combination of objective measures (e.g., time (WPM), error rates) as well as subjective measures (e.g., user satisfaction, acceptance, preference among methods, likelihood to use) should be examined.",Medium,This topic examines the overall issue of text input using AR experiences and interfaces with a wearable AR display device. It is expected that researchers will examine one of the aforementioned methodologies and not all in a single study. The research is best done in controlled environments to determine optimal performance before generalizing to applied settings. Time and motion studies could be employed for performance assessment/metrics. Interviews and surveys are needed to explore user acceptance of different text input options.,User performance and subjective data of text input using a HoloLens device can be seen in https://journals.sagepub.com/doi/pdf/10.1177/1071181319631279/[this article].,ERAU Team,8/31/2021,3.84,"Xu, W., Liang, H.-N., He, A., & Wang, Z. (2019). Pointing and Selection Methods for Text Entry in Augmented Reality Head Mounted Displays. 2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). URL: https://doi.org/10.1109/ismar.2019.00026 | Dudley, J. J., Vertanen, K., & Kristensson, P. O. (2018). Fast and Precise Touch-Based Text Entry for Head-Mounted Augmented Reality with Variable Occlusion. ACM Transactions on Computer-Human Interaction, 25(6), 1-40. URL: https://doi.org/10.1145/3232163 | Pathmanathan, N., Becher, M., Rodrigues, N., Reina, G., Ertl, T., Weiskopf, D., & Sedlmair, M. (2020). Eye vs. Head: Comparing Gaze Methods for Interaction in Augmented Reality. ACM Symposium on Eye Tracking Research and Applications. URL: https://doi.org/10.1145/3379156.3391829 | Marques, B., Carvalho, R., Dias, P., & Santos, B. S. (2019). Pervasive augmented reality for indoor uninterrupted experiences. Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers. URL: https://doi.org/10.1145/3341162.3343759 | De S Ribeiro, M. G., Mazuecos, I. L., Marinho, F., & dos Santos, A. N. G. (2019). Agile Explorations in AR. IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society. URL: https://doi.org/10.1109/iecon.2019.8926838"
12,Facilitated User Interactions for Selecting and Manipulating 3D Models in AR,"Computer-generated models and models derived from scans of objects are increasingly part of product designs and testing activities. They are also valuable in diagnostics, and guiding assembly, repair and maintenance procedures. Today, many AR experiences use only 2D targets and display 2D line drawings, text, and images. However, in the future 3D models will increasingly be used for object recognition, tracking, and registration of experiences. Models will also be displayed over real-world objects for instructions or ""hanging"" in space when two or more collaborators need to examine the same object. Users will need to manipulate and interact with the models.

Unfortunately, the tools (e.g., pointing devices) and conventions (e.g., gestures and voice commands) for the selection and manipulation of 3D models in AR are unfamiliar and challenging for users. Most models lack clearly labelled anchors, handles, and other indicators that would reduce the barriers to user interactions. When there are multiple models in a scene, users may be unable to select one for closer examination. Users must learn advanced techniques and concentrate to perform simple manipulations such as open, close, and hide, not to mention advanced manipulations such as rotate, scale (enlarge and shrink), attach, move to back, move forward and other actions that may increase the value of a model in AR experiences.

This research topic focuses on the design, development, and evaluation of computer-human interactions and computer graphic techniques to improve the ease-of-use of 3D models in AR experiences. When research results are published in peer-reviewed journals, there will be greater diversity in solutions and more innovation based on a deeper understanding of the options and trade-offs involved.

","3D models, selection, manipulation, anchors, labels, handles, rotation, scale, attach, human computer interaction, computer human interaction, computer graphics, computer human interaction, computer graphics","Technology, End User and User Experience","This research is relevant to designers and managers of enterprise 3D assets, 3D asset platform publishers, AR experience developers, AR program managers, and AR authoring platform publishers.","- AR experience developers and employees in AREA customer segment companies will have many use cases involving the selection and manipulation of 3D models. However, the acceptance and value of 3D models will be low until there are improvements in how models are prepared, presented and manipulated during AR experiences.
- The proposed research topic will benefit AREA members by increasing 3D model usability, lowering cognitive load, and increasing the impact of 3D models in the workplace.","The research will build and publish a set of 3D models that objectively represent what would be used in workplace settings where AR is used. The models will be designed with features such as anchors and handles. Studies will compare approaches developed in commercial software for 2D screens with those proposed in AR and VR game engines and experience authoring platforms. In laboratory settings, users will be given tasks to perform with 3D models while using different models of wearable AR displays. In addition to time-motion studies and ergonomics, user testing will measure strain and cognitive effort when performing tasks that require model selection and manipulation.",Near,"This research topic could be combined with studies of 3D capture, computer graphics, and 3D model registration and annotation. Research pertaining to AR user interfaces and interaction could also be extended to include 3D model selection and manipulation. The study of hand tracking would contribute to exploring use of gestures for simple and advanced model usage.","Microsoft has published several papers and best practices on this for HoloLens, hand tracking, and gestures, but these are exclusively implemented in one platform and there has not been extensive comparison using quantitative methods. This topic was proposed for consideration in 7th AREA research project topic call and received high member interest and support.",Christine Perey,8/31/2021,4,"Fradi, A., Louhichi, B., Mahjoub, M. A., & Eynard, B. (2017). 3D Object Retrieval Based on Similarity Calculation in 3D Computer Aided Design Systems. 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications (AICCSA). URL: https://doi.org/10.1109/aiccsa.2017.101 | Khedwala, M., Momin, F., Pachhapure, U., & Shaikh, S. (2018). Analysis of Auto Generation of 3D Model Using Multiple 2D Graphics to Manifest Through Augmented Reality. 2018 International Conference on Smart City and Emerging Technology (ICSCET). URL: https://doi.org/10.1109/icscet.2018.8537310 | Feng, L., Yang, X., & Xiao, S. (2017). MagicToon: A 2D-to-3D creative cartoon modeling system with mobile AR. 2017 IEEE Virtual Reality (VR). URL: https://doi.org/10.1109/vr.2017.7892247 | Weng, M., Kong, X., Huang, L., & Li, B. (2018). A Low-Cost Wireless System Implementation for Interactive and Immersive Teaching. Proceedings of the Eighteenth ACM International Symposium on Mobile Ad Hoc Networking and Computing. URL: https://doi.org/10.1145/3209582.3225208 | Nguyen, M., Lai, M. P., Le, H., & Yan, W. Q. (2019). A Web-based Augmented Reality Platform using Pictorial QR Code for Educational Purposes and Beyond. 25th ACM Symposium on Virtual Reality Software and Technology. URL: https://doi.org/10.1145/3359996.3364793"
13,What Factors Influence Perceptions of Presence?,"Presence is a term used to describe the ""feeling of being there"" in a virtual environment. It can be cognitive, in that the user's mind is engaged in the virtual content, or it can be perceptual, in that the user's sensory systems perceive the virtual environment to be ""real."" In Augmented Reality (AR), this is represented by a seamless integration between the physical and virtual worlds.

A question that arises in this area of research is what factors of the virtual environment influence the perceptions of presence? Is there a minimum amount of virtual information needed in an AR environment? Does the level of fidelity of the virtual elements influence the reported experience of presence? For example, will an application that uses realistic 3D models result in higher levels of presence than lower fidelity (i.e., cartoon) 3D models?

In VR worlds, the user is immersed into a completely virtual world, so presence is likely to be experienced if the application is successfully implemented. In AR environments, users are exposed to virtual elements in addition to their physical surroundings. If a user has to switch their attention between the two worlds to complete a task, the result can be disruptive and/or fatiguing due to the lack of presence. If the user can complete the task as if the virtual elements are part of the physical world, the result is a seamless, productive experience that includes presence. It also is possible that lower fidelity serves as a distraction to the user, which may result in breaks in immersion and a reminder of the artifical nature of the virtual world. This could, in turn, impact their sense of presence.

A practical example of this issue is with the use of avatars in collaborative environments. How is presence affected by the appearance and customization of the avatars? If a user pays attention to a particular feature or abnormality due to low fidelity rendering, it may impact their ability to perform the task at hand. Another example may be dynamic elements in the virtual world, such as a bouncing ball or a spinning tire. How distinguishable, in appearance and in behavior, the object is from its physical counterpart may influence the level of reported presence.

The main research question in this area is ""How much virtual information of what fidelity is necessary in an AR environment to produce a sense of presence?"" This question is of interest at both ends of the quantity spectrum -- how much is enough, and how much is too much? Too little and the user will not experience presence; too much and the user may become so immersed in the virtual elements that awareness of the physical world may be compromised.

This research topic involves the examination of AR environments with differing amounts of virtual elements at different levels of fidelity and the measurement of presence among users.

","presence, immersion, awareness, realism, cognitive tunneling, mental workload, seamless experience, high fidelity, low fidelity, realism, avatars, object interaction, display technology, presence, interactive computer graphics, user experience, cognitive systems, sensory perception, avatars, computer graphics, color computer graphics, holographic displays, animation, image quality","End User and User Experience, Industries, Technology","Developers, users, operators, users of collaborative virtual environments

# Position on X and Y axes (1-5)",#NAME?,"Presence tends to be a self-reported measure assessed by means of a questionnaire. Physiological measures also may be explored to correlate with reported presence, engagement, and satisfaction. These measures could be systematically compared across environments of varying complexity in terms of number of virtual stimuli for a variety of tasks.",Medium,This topic is related to other proposed AREA Research Agenda topics on display technology and user perceptions and satisfaction.,An interesting article related to the amount of physical space in which AR application is used can be found https://ieeexplore.ieee.org/document/8943577/[here].,ERAU Team,8/31/2021,4.07,"Szczurowski, K., & Smith, M. (2017). Measuring presence: Hypothetical quantitative framework. 2017 23rd International Conference on Virtual System & Multimedia (VSMM). URL: https://doi.org/10.1109/vsmm.2017.8346261 | Koskela, T., Mazouzi, M., Alavesa, P., Pakanen, M., Minyaev, I., Paavola, E., & Tuliniemi, J. (2018). AVATAREX. Proceedings of the 9th Augmented Human International Conference. URL: https://doi.org/10.1145/3174910.3174926 | Rhee, T., Thompson, S., Medeiros, D., dos Anjos, R., & Chalmers, A. (2020). Augmented Virtual Teleportation for High-Fidelity Telecollaboration. IEEE Transactions on Visualization and Computer Graphics, 26(5), 1923-1933. URL: https://doi.org/10.1109/tvcg.2020.2973065 | Merenda, C., Suga, C., Gabbard, J. L., & Misu, T. (2019). Effects of ""Real-World"" Visual Fidelity on AR Interface Assessment: A Case Study Using AR Head-up Display Graphics in Driving. 2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). URL: https://doi.org/10.1109/ismar.2019.00-10 | Poretski, L., Arazy, O., Lanir, J., Shahar, S., & Nov, O. (2019). Virtual Objects in the Physical World. Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. URL: https://doi.org/10.1145/3290605.3300921"
14,Impact of Individual Differences and AR Display Comfort on User Acceptance,"Head-mounted AR display devices are getting lighter and more comfortable. However, users may still perceive the weight on their necks and find the devices cumbersome to don and doff, as well as finding them hot after extended periods of use. Head sizes, head shapes, visual acuity, inter-pupillary distance, and the use of corrective lenses or safety glasses/safety helmets all affect users' comfort and ease of use. While advances in the technology that accommodate wider ranges of users are rapidly being deployed, industry adoption can be hampered by poor user acceptance due to general discomfort.

This research topic examines impacts of individual differences on user satisfaction and acceptance of a variety of HMD devices in the workplace.

","comfort, eye strain, fatigue, simulation sickness, heat tolerance, headgear weight tolerance, subjective testing, behavioral research, thermal comfort, environmental factors, comfort","End User and User Experience, Industries, Technology","Developers, users, operators, users of AR head mounted displays (HMDs)",#NAME?,"Comfort can be measured both objectively and subjectively. Objective measures include pupil diameter to assess workload or cognitive effort, EEG, and GSR. Subjective measures include Likert scales querying perceived comfort, exertion (i.e., Borg Scale or Perceived Exertion), assessments of HMD weight, thermal comfort, acceptable length of use, and general acceptance.",Medium,This topic is potentially related to another proposed AREA Research Agenda topic on Users and User Experience [Einput-textinput] in that comfort is a key component to user acceptance of various text input methods. The topics could be combined with other AR End User and User Experience topics to develop a full research program.,An interesting article regarding the design decisions of the HoloLens 1 to accommodate individual differences https://sid.onlinelibrary.wiley.com/doi/pdf/10.1002/sdtp.11586?casa_token=i1x9dRJa2tAAAAAA%3AmnQU3ckNbdunIDNe4G8uxoLfe87YwzEpS7Ti1G0N9L76PgNLHarmCNusU9C9U9ucswKxB3wtRUFUdyM/[can be found here].,ERAU Team,8/31/2021,2.39,"Marques, B., Carvalho, R., Dias, P., & Santos, B. S. (2019). Pervasive augmented reality for indoor uninterrupted experiences. Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers. URL: https://doi.org/10.1145/3341162.3343759 | Lins, E. A., De Castro, A., Frohlich, F., Bertoletti De Marchi, A. C., & Rieder, R. (2017). Interactivity and Immersion Evaluation on Smartphones. 2017 19th Symposium on Virtual and Augmented Reality (SVR). URL: https://doi.org/10.1109/svr.2017.23 | De S Ribeiro, M. G., Mazuecos, I. L., Marinho, F., & dos Santos, A. N. G. (2019). Agile Explorations in AR. IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society. URL: https://doi.org/10.1109/iecon.2019.8926838 | Alqahtani, H., & Kavakli, M. (2017). A theoretical model to measure user's behavioural intention to use iMAP-CampUS app. 2017 12th IEEE Conference on Industrial Electronics and Applications (ICIEA). URL: https://doi.org/10.1109/iciea.2017.8282928 | Vaquero-Melchor, D., & Bernardos, A. M. (2019). Alternative interaction techniques for drone-based mission definition. Proceedings of the 18th International Conference on Mobile and Ubiquitous Multimedia. URL: https://doi.org/10.1145/3365610.3368420"
15,Visualization of Targets Invisible Due to Atmospheric Conditions,"When conditions prevent mechanical or visual scanning of environments and providing of situational awareness using vision-based technologies, there need to be alternatives. The goal of this research is to provide users (decision makers such as pilots, drivers of cars or vehicles, operators of equipment at night or in blizzard conditions) an accurate visualization of the real-time conditions of a moving machine (e.g., automobile, aircraft, tank, truck) when the surrounding atmosphere is entirely or nearly opaque or the light conditions are not favorable for use of vision-based sensors.

Although identified/scored as an aviation-industry specific topic, the scope of this topic is very broad and results could be applied in many industries (e.g., automotive). The topic spans everything from the use of non-visual sensors (e.g., sonar) for depth to the development of new computer-human interfaces for 3D data visualization.

","situational awareness, night vision, non-visual scanning in real time, aviation and aerospace, military, reconnaissance, occlusion, depth of field, automotive, sensor fusion, data layers, ToF (Time of Flight) sensors, computer vision, autonomous vehicles, user experience, night vision, aircraft navigation, avionics, aircraft displays, air navigation, aircraft detection, automotive, user experience","Industries, Displays, Technology","AR experience developers, operators and owners/users of commercial, private or military aircraft",#NAME?,"Acquisition and/or development of lightweight and power-efficient infrared sensors that are effective as alternatives to cameras and existing vision-based environmental capture. Testing and development of 3D interaction modes when user's natural vision is impaired. This research topic could explore IR sensors (which measure differences in temperature, also known as ""thermal imaging""), as well as new alternatives.",Medium,"This topic of research overlaps with the topic of using AR to visualize any stationary or moving object in low-visibility conditions. The outcomes of this research could also be applied in non-industrial use cases (e.g., skiing or other sports in low visibility-conditions). The same research topic could be combined with study of user interfaces and interaction paradigms for the visually impaired community.",The use of night vision technologies is widespread in the military/defense industry. There have also been studies of the use of AR for https://sciencebusiness.net/network-news/air-traffic-control-improved-augmented-reality[air traffic control].,Christine Perey,8/31/2021,2.46,"Ciocoiu, T. I., & Moldoveanu, F. D. (2017). Vision based localization stereo rig calibration and rectification. 2017 International Conference on Optimization of Electrical and Electronic Equipment (OPTIM) & 2017 Intl Aegean Conference on Electrical Machines and Power Electronics (ACEMP). URL: https://doi.org/10.1109/optim.2017.7975103 | He, Y., & Chen, S. (2019). Recent Advances in 3D Data Acquisition and Processing by Time-of-Flight Camera. IEEE Access, 7, 12495-12510. URL: https://doi.org/10.1109/access.2019.2891693 | Pascoal, R. M., de Almeida, A., & Sofia, R. C. (2019). Activity recognition in outdoor sports environments. Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers. URL: https://doi.org/10.1145/3341162.3349299 | Zhao, Y., Kupferstein, E., Castro, B. V., Feiner, S., & Azenkot, S. (2019). Designing AR Visualizations to Facilitate Stair Navigation for People with Low Vision. Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology. URL: https://doi.org/10.1145/3332165.3347906 | Park, Y. J., Ro, H., Byun, J.-H., & Han, T.-D. (2019). Adaptive projection augmented reality with object recognition based on deep learning. Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion. URL: https://doi.org/10.1145/3308557.3308678"
16,Visualization of Temperature Sensor Data in AR for Emergency Response,"The use of thermal imaging data from handheld devices for identification of bodies in smoke-filled spaces has been in use to save lives for decades. This topic is not intended to study that use case. Several companies have successfully integrated the thermal imaging sensors into commercial PPE (""smart helmets"") worn by emergency responders.

This research topic will instead focus on advancing the state of the art of thermal vision. There could be extension of the types and size of thermal imaging technology suitable for including in AR-assisted emergency responses equipment. Currently, thermal imaging produces data in only 2D. Research into visualizing the heat source in 3D will be beneficial. In addition, the research should explore different methods for users to interact with the data displayed on their helmets, new and novel methods of distinguishing between heat-emitting sources detected using thermal imaging and combining the information about a building's floor plan with the thermal imaging to trace safe routes to use when reaching targets under time constraints.

","thermal imaging, 3D data visualization, smart helmets, Personal Protective Equipment, fire fighting, route tracing, 3D data interaction, public safety, ","Industries, Displays, Technology","While the emergency responder and military use cases are the clear beneficiaries of this research topic, there are also applications in automotive, such as displaying to a driver moving or stationary wildlife along a road side or forklift drivers ""seeing"" the thermal image of pedestrians in a warehouse or in a manufacturing environment. Additional imaging could prevent hazardous interactions. Similarly, when mounted in field equipment, the AR display can alert a driver to the presence of people or animals in the path of the equipment. When the technology is miniaturized and highly reliable, it may be used in enterprise AR use cases including but not limited to medical industry or animal husbandry for diagnostics and therapeutics. If the cost and size of the technologies is sufficiently low, the feature could be used for non-industrial applications, such as in games or education.",#NAME?,"The study of thermal imaging and design of new sensors for heat mapping will involve expertise in physics and engineering. Adapting new sensors to fit the AR display form factors for prototyping and user testing will require skills in electromechanical domains, semiconductors, and industrial design. In addition to research about thermal sensors, there will need to be research on user interaction with 3D thermal images.",Medium,"This topic can be combined with studies of other sensors that permit users to visualize through water, atmospheric conditions, and physical obstructions (e.g., walls). The study of sensor integration could also be extended to span visualization of a user's vitals (heart beat, blood pressure, etc.) and 3D interactions.","This topic was the focus of work by students at EPFL (Switzerland) in 2015. The students working on this project https://actu.epfl.ch/news/augmented-reality-for-firefighters/[developed a thermal imaging smart visor] in 2016.

There was also a http://fayez.me/papers/ICIP-2018-Paper.pdf[peer-reviewed journal paper] published by one of the EPFL faculty working on the above project in 2018.

In 2019, Darix, the start-up that was created out of the EPFL research, https://actu.epfl.ch/news/ic-spinoff-darix-acquired-by-bullard/[was acquired by Bullard].

Longan Vision, another company in this field, has been https://spectrum.ieee.org/the-institute/ieee-member-news/startups-thermal-imaging-and-ar-system-for-firefighters-joins-the-covid19-fight[adapting their system for Covid].",Christine Perey,8/31/2021,2.57,"Erickson, A., Kim, K., Schubert, R., Bruder, G., & Welch, G. (2019). Is It Cold in Here or Is It Just Me? Analysis of Augmented Reality Temperature Visualization for Computer-Mediated Thermoception. 2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). URL: https://doi.org/10.1109/ismar.2019.000-2 | Kang, S., Choi, H., Park, S., Park, C., Lee, J., Lee, U., & Lee, S.-J. (2019). Fire in Your Hands. The 25th Annual International Conference on Mobile Computing and Networking. URL: https://doi.org/10.1145/3300061.3300128 | Hirai, S., & Miki, N. (2019). Thermal Sensation Display with Controllable Thermal Conductivity. 2019 20th International Conference on Solid-State Sensors, Actuators and Microsystems & Eurosensors XXXIII (TRANSDUCERS & EUROSENSORS XXXIII). URL: https://doi.org/10.1109/transducers.2019.8808369 | Mady, A. S., & Abou El-Seoud, S. (2020). An Interactive Augmented Reality Volume Rendering Mobile Application. Advances in Intelligent Systems and Computing, 888-896. URL: https://doi.org/10.1007/978-3-030-49932-7_82 | Kraus, V., & Uzun, Y. (2020). Supporting Medical Auxiliary Work: The Central Sterile Services Department as a Challenging Environment for Augmented Reality Applications. 2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). URL: https://doi.org/10.1109/ismar50242.2020.00096"
17,AR for Crop Preservation in Food-Insecure Countries,"Food and nutrition security remains a huge challenge across the globe, particularly as the frequency of extreme climate events increases. The Integrated Food Security Phase Classification (IPC) indicates the level of hunger/starvation present in a particular country or region due to insufficient crop supply. The Food Security and Sustainable Agriculture (FSSA) ""resilience-building thematic mechanism aims to ensure the complementarity of instruments for high-impact aid. It had an indicative budget of Ã¢ÂÂ¬525 million over the 2014-2020 period."" Additionally, ""sustainable food security"" remains a priority for the world economy, with the EU Project Horizon 2020 work programme identifying the following immediate needs for further research and innovation:
- Identification of tools and methods, mainly at the farm level for soil remediation and balanced fertilizers application;  +
- Identification of agricultural system approach that can enhance quality of soils for food production; +
- To raise public awareness about soil as a crucial global resource; +
- Enhance EU-China long-term cooperation in land use optimization for global food and environmental security.

This research topic focuses on how AR can be used to permit farmers to investigate their crops, while layering additional information such as water saturation metrics from IoT data, as well as even potentially an AI component that could categorize types of erosion and/or plant disease and provide real-time feedback with regards to required human intervention. The use of AR in agriculture could be adopted or subsidized by fertilizer corporations, water providers, and other members of an agriculture ecosystem. When those in the field use AR, providers of products and services would be able to connect from a distance and provide real-time advice for farmers and other end-clients.

This study would aim to specifically measure the impact of data-informed AR on crop preservation, particularly in food-insecure countries.

","United Nations, Sustainable Development Goals, sustainability, policy, education, skill development, socio-economic effects, artificial intelligence, IoT, crop preservation, farming, agriculture, water preservation, social aspects, social and economic effects","Business, End User and User Experience, Industries","Government officials and policymakers in World Bank Group and UN nations, social performance and impact executives in large, global organizations, particularly those with a large social license to operate, sustainability/innovation groups in large corporations, executives and sales teams in agriculture","- AR can provide a vital channel with which to establish a vibrant food production ecosystem positioned to support and connect farmers across the world.
- Large impact can be made by utilizing existing soil/plant photography databases and AI-driven, AR-facilitated guidance, as well as incorporation of IoT data pertaining to water availability, as many food-insecure nations experience hardship associated with frequent drought.
- AR is a unique delivery format that is highly conducive to providing increased accessibility for remote, rural farmers and lowers traditional barriers associated with varying literacy levels, etc.,
- Introduction of AR opens up a myriad of possibilities with regards to establishing and expanding markets.
- There is likely to be substantial interest within local governments as well as amongst corporate entities supporting the UN 2030 Sustainable Development Goals. There is also great potential for interest amongst providers within the broader agriculture value chain.","The proposed research would need to enroll and engage rural farmers in food-insecure areas, preferably those in which agriculture is practiced in remote or at-risk locations (e.g. retired mine site, etc.). The research would also need to develop or expand and leverage databases of photos for local plant and soil conditions.

Rural farmers would need to be onboarded into technology pilots, and potential ecosystem partners (e.g. water providers, fertilizer providers, etc.) would need to be identified. The principal investigator would develop partnerships with a host corporation and community. Research would include IoT data pre- and post- introduction of AR intervention via A/B trial scenarios, potentially with a few different levels of AR intervention. Then researchers would collect data about post-intervention behaviors and crop status.

Post-study outcomes could be analyzed and recommendations developed for future implementation.",Near,"This study could also be extended to explore benefits in the mining industry, when mine sites are retired, as AR could help companies ensure that the communities in the process of transitioning to different revenue sources have the tools that they need to ensure the sustainability of the land post-asset. Additionally the research methods could be extended or support other research programs associated with metals and mining, water preservation, education, policy, upskilling, and sustainability.",https://ec.europa.eu/research/participants/data/ref/h2020/wp/2018-2020/main/h2020-wp1820-energy_en.pdf[Crop preservation research recommendations] published by the European Union provide support for this research topic.,Jennifer Rogers,8/31/2021,1.42,"Babu, N. S. C. (2017). Keynote 1: Internet of Things(IoT) and augmented reality for e-learning. 2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH). URL: https://doi.org/10.1109/eleltech.2017.8074987 | Xi, M., Adcock, M., & McCulloch, J. (2018). Future Agriculture Farm Management using Augmented Reality. 2018 IEEE Workshop on Augmented and Virtual Realities for Good (VAR4Good). URL: https://doi.org/10.1109/var4good.2018.8576887 | Al Akil, D., Ahmed, V., & Saboor, S. (2020). The Utilization of Augmented Reality Technologies within the Engineering Curricula - Opportunities and Challenges. 2020 IFEES World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC). URL: https://doi.org/10.1109/weef-gedc49885.2020.9293626 | Sonderegger, A., Ribes, D., Henchoz, N., & Groves, E. (2019). Food Talks: Visual and Interaction Principles for Representing Environmental and Nutritional Food Information in Augmented Reality. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00040 | Todorovic, V., Milic, N., & Lazarevic, M. (2019). Augmented Reality in Food production traceability - use case. IEEE EUROCON 2019 -18th International Conference on Smart Technologies. URL: https://doi.org/10.1109/eurocon.2019.8861734"
18,Remote Plant Design and Onboarding with AR,"As research and development centers increasingly focus on implementing scalable industrial solutions on a global scale, it is difficult to ensure that, once new technologies are created and tested in a constrained environment, subject-matter experts can always travel to all the required plant locations.

Remote assistance or collaboration with AR-enhanced local technicians permits subject-matter experts to view a new installation and to support local staff with operation of new technology onsite. Remote experts may advise local users and, where necessary, support specific operational decisions that must be taken rapidly due to the specific site configuration and requirements (e.g. best equipment layout to drive operational efficiency, adjustments due to specific environmental requirements or regulations, etc.).

This research topic seeks to specifically measure time and cost benefits to new site operational readiness, as well as initial operational effectiveness, associated with AR- and non-AR assisted technology commercialization projects.

","Operational readiness, Operational effectiveness, Research and development, R&D, cost effectiveness, cost reduction, industrial research. technology, remote operations, decision support systems, failure, indicators, just in time, mixed realities, optimisation","Business, End User and User Experience, Use Cases","This research will provide operational excellence professionals, chief operating officers, safety and risk professionals, and plant managers quantitative information that will permit them to make better decisions about where and how to introduce AR in plants.",#NAME?,The proposed research would need to identify key operational decisions and processes required for transfer from R&D to on-site operations. Research would measure time and cost to site operation with AR-assisted intervention and compare to known historical ramp-up times and costs.,Near,"This study could link closely with existing research programs associated with metals and mining, oil and gas, aerospace, manufacturing, and operational excellence in general.","Example of use cases:
https://www.cidrap.umn.edu/news-perspective/2021/02/who-pushes-covid-vaccine-production-scale-more-sharing +
https://apnews.com/press-release/pr-newswire/business-technology-lifestyle-products-and-services-jewelry-0c4c7956edd2d3f918f330a29ef59567 +",Jennifer Rogers,8/31/2021,1.73,"Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Schmalstieg, D. (2018). VIS Keynote Address : When Visualization Met Augmented Reality. 2018 IEEE Conference on Visual Analytics Science and Technology (VAST). URL: https://doi.org/10.1109/vast.2018.8802427 | Chen, L., Wang, W., Qu, J., Lei, S., & Li, T. (2020). A Command and Control System for Air Defense Forces with Augmented Reality and Multimodal Interaction. Journal of Physics: Conference Series, 1627, 012002. URL: https://doi.org/10.1088/1742-6596/1627/1/012002 | Lv, Y. (2020). Application Analysis of Computer Augmented Reality (AR) Technology in Landscape Design of Rural Revitalization. IOP Conference Series: Materials Science and Engineering, 750, 012153. URL: https://doi.org/10.1088/1757-899x/750/1/012153 | Babu, N. S. C. (2017). Keynote 1: Internet of Things(IoT) and augmented reality for e-learning. 2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH). URL: https://doi.org/10.1109/eleltech.2017.8074987"
19,"Cargo Container Loading, Inspection and Management with AR","Containers play an important role in the transportation of goods by sea and air. There are a variety of ways that AR can assist employees to track and manage containers on a vessel, airplane or in port. Where there are risks there are also opportunities. By having information about the status of containers, as well as the weight, shape and type of contents of containers in an AR-ready database, technicians can make better informed decisions.

An example of this is cold chain management. Containers with climate control are used to preserve and to extend and ensure the shelf life of products, such as fresh agricultural produce, frozen food, chemicals, and pharmaceutical products. Depending on the specific product, other physical parameters of the chain may also be regulated, (e.g. CO2/oxygen level, humidity and others).

Cold chain governance requires continuous monitoring and/or RFID tags to document the temperature history down to the container level. If a cold chain breaks, it is paramount to identify effected cargo as such and remove it from further shipping as soon as possible. Head mounted displays, or handheld devices can track unloading cargo and - pulling the data from the containerÃ¢ÂÂs data logger - visually identify non-compliant containers. This visualization allows for an efficient way of isolating non-compliance or other mismatches.

Stowage is another example. When loading merchant vessels, air cargo, or another shipping instrument, weight distribution is carefully calculated and loading is planned accordingly. These stowage plans are critical to vessel stability therefore compliance is very important. Although stowage or loading plans are delivered by various software tools, execution is dependent on human interaction.

Head mounted displays, handheld devices or stationary cameras can track loading cargo using computer vision, container marking (e.g. QR codes), RFID or other dedicated sensor networks. When loading is finished, cargo distribution can be projected on a digital representation of a vessel. This visualization allows for an efficient way to identify potential non-compliance or other mismatches leading to lower efficiency or risks.

This research topic focuses on documenting use cases for enriching the interactions that AR-enabled technicians, on board, during loading and in port, can have and decisions they may make when receiving and using accurate and up-to-date information about containers and their contents. As the professionals move about within and around containers when loading, inspecting, maintaining or repairing commercial containers, they will be more productive, and security and safety policy compliance can increase.

","marine, logistics, shipping, freight, cold chain, commercial shipping, containers, tracking, ships, cargo airplanes, technicians, port operations, cargo loading, inspection, safety, security, stowage plan, loading order, weight distribution, track and trace, sensors, data fusion, cargo, marine, ships, buoyancy, ambient intelligence, mechatronics, internet of things","Industries, Business, Technology","Operators of any cargo service including but not limited to shipping services, pilots, naval captains, shipping operations managers, quality managers, security managers, workers performing repair and maintenance on shipping containers, port operations, customs agents",#NAME?,"This research requires a team of experts intimately familiar with all aspects of the transportation of goods. The study of regional as well as global shipping patterns and technologies will be followed by development of prototypes and testing in a variety of settings. In field usability trials, with service professionals can reveal new requirements and opportunities for AR-assisted and IoT connected containers to reduce risk and increase productivity.",Medium,"This topic or theme of research overlaps with other topics pertaining to management of goods and services and use cases that benefit from users being able to quickly obtain information about any closed but connected container on land or sea. Research can be combined with assessments of accuracy at a distance from the target. The study of AR in commercial ports could have impacts on customs clearance and compliance with regulatory policy (e.g., safety, duties, etc).","Western Container Sales, a container retailer, https://westerncontainersales.com/augmented-reality-shipping-container/[offers AR experiences for prospective customers].","Christine Perey, Peter Orban",8/31/2021,0.38,"Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Mukhametshin, S., Makhmutova, A., & Anikin, I. (2019). Sensor Tag Detection, Tracking and Recognition for AR Application. 2019 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM). URL: https://doi.org/10.1109/icieam.2019.8743017 | Babu, N. S. C. (2017). Keynote 1: Internet of Things(IoT) and augmented reality for e-learning. 2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH). URL: https://doi.org/10.1109/eleltech.2017.8074987 | Schmalstieg, D. (2018). VIS Keynote Address : When Visualization Met Augmented Reality. 2018 IEEE Conference on Visual Analytics Science and Technology (VAST). URL: https://doi.org/10.1109/vast.2018.8802427 | Butkiewicz, T., & Stevens, A. H. (2020). Evaluation of the effects of field-of-view in augmented reality for marine navigation. Optical Architectures for Displays and Sensing in Augmented, Virtual, and Mixed Reality (AR, VR, MR). URL: https://doi.org/10.1117/12.2546605"
20,Visualization of Anything of Interest Below Water Surface,"When conditions prevent visual scanning of environments and providing situational awareness using vision-based technologies, there need to be alternatives. The goal of this research is to provide users (decision makers such as operators of any boat or underwater craft) an accurate visualization of the real-time conditions of an operating (moving) machine (e.g., boat, submarine) when the visibility prevents reliable use of vision-based sensors.

Although identified/scored as a marine industry specific project, the scope of this topic is very broad and results could be applied in many industries. The topic spans everything from the use of non-visual sensors (e.g., sonar) for depth to the development of new computer-human interfaces for 3D data visualization.

","situational awareness, night vision, non-visual scanning in real time, marine, rescue, emergency response, autonomous underwater vehicles, marine navigation, marine radar","Industries, Technology","Developers, operators and owners/users of commercial, private or military water craft",#NAME?,A research platform would be designed of lightweight and power efficient sensors that are effective as alternatives to cameras and existing vision-based environmental capture. The research would test and develop 3D interaction modes when a user's natural vision is impaired.,Medium,"This topic or theme of research overlap with the topic of visualizing conditions in the direction or on the path of any moving object. The outcomes of this research could also be applied in non-industrial use cases (e.g., scuba diving or other sports in low visibility conditions). The same research topic could be combined with study of user interfaces and interaction paradigms for the visually-impaired community.",None,Christine Perey,8/31/2021,1.6,"Ciocoiu, T. I., & Moldoveanu, F. D. (2017). Vision based localization stereo rig calibration and rectification. 2017 International Conference on Optimization of Electrical and Electronic Equipment (OPTIM) & 2017 Intl Aegean Conference on Electrical Machines and Power Electronics (ACEMP). URL: https://doi.org/10.1109/optim.2017.7975103 | He, Y., & Chen, S. (2019). Recent Advances in 3D Data Acquisition and Processing by Time-of-Flight Camera. IEEE Access, 7, 12495-12510. URL: https://doi.org/10.1109/access.2019.2891693 | Zhao, Y., Kupferstein, E., Castro, B. V., Feiner, S., & Azenkot, S. (2019). Designing AR Visualizations to Facilitate Stair Navigation for People with Low Vision. Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology. URL: https://doi.org/10.1145/3332165.3347906 | Park, Y. J., Ro, H., Byun, J.-H., & Han, T.-D. (2019). Adaptive projection augmented reality with object recognition based on deep learning. Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion. URL: https://doi.org/10.1145/3308557.3308678 | Azenkot, S., & Zhao, Y. (2017). Designing smartglasses applications for people with low vision. ACM SIGACCESS Accessibility and Computing, (119), 19-24. URL: https://doi.org/10.1145/3167902.3167905"
21,Adoption of AR in Metals and Mining Value Chain,"As an industry that has thus far been slower to adapt to automation, mining finds itself at a crossroads with regards to the recent COVID pandemic, in that companies must redesign working environments to accommodate for the a) lack of available on-site skilled labor available to sustain current operations, b) mandates to reduce proximity of individuals, and thus number of crew members on site, and c) retraining and upskilling of current workforce as automation accelerates.

This research topic aims to describe the manner in which employment and crew models can be reconstructed to reduce risk to the overall mining value chain and preserve operational targets so as to prevent wide-scale economic impact to the world economy.

","metals and mining, employment, recovery, COVID, crew models, remote operations, risk reduction, human resources, metalworking, ore treatment,","Industries, Business, End User and User Experience","Economists, government officials in countries with heavy mining production, senior executives in metals/mining, HR professionals, social performance professionals, and operational excellence professionals will be impacted by this research.","- Mining is an industry that is incredibly important to the world economy and has been challenged greatly by the recent COVID pandemic. Lessons learned tell us that the industry needs to do a much better job of preparing for ""black swan"" events and the challenges that it presents to the entire mining value chain.
- By identifying crew models that reduce physical proximity and allow for reduction of risk across the mining value chain, many recommendations recently put forth by the Intergovernmental Forum on Mining, Minerals, Metals, and Sustainable Development can be immediately put into practice.",Survey key stakeholders to identify areas of opportunity within the categories of employment and areas of mining value chain represented on page 3 of the IGF report (https://www.iisd.org/system/files/publications/covid-19-employment-mining-en.pdf). Construct a series of AR-assisted employment models to drive specific improvement and employment resilience across the mining value chain.,Near,"This study potentially links to another proposed study around impact of AR on Multidimensional Poverty Index (MPI). This study could link closely with existing research programs associated with remote operations support and decision-making, as well as any programs around business impact and measures. It also relates to AR as an upskilling mechanism to assist with employment during increasing industry automation.","From the IGF report, ""Large-scale mining plays a critical economic and social role in remote areas. Large-scale mining activities are localized in remote areas with underdeveloped or few major alternative economic sectors. Mining plays a critical role for host communities, where it is often the largestÃ¢ÂÂif not the soleÃ¢ÂÂjob creator and provider of vital services, including a variety of social services, such as health care and education. Large-scale mining creates more business in host countries. Mining activities have significant multiplier effects on the local and national economy through the creation of indirect and induced employment and business opportunities. ICMM3 estimates those opportunities can contribute up to 15% of national income in certain countries."" This https://www.iisd.org/system/files/publications/covid-19-employment-mining-en.pdf[IGF Study] describes the issues facing the industry that could be addressed in part with adoption of AR.",Jennifer Rogers,8/31/2021,0.14,"Woltering, T., Sardoux Klasen, A., & Feldmann, C. (2020). Augmented Reality in the Packing Process: A Model for Analyzing Economic Efficiency. Lecture Notes in Logistics, 493-503. URL: https://doi.org/10.1007/978-3-030-44783-0_46 | Kiziroglou, M. E., Boyle, D. E., Yeatman, E. M., & Cilliers, J. J. (2017). Opportunities for Sensing Systems in Mining. IEEE Transactions on Industrial Informatics, 13(1), 278-286. URL: https://doi.org/10.1109/tii.2016.2636131 | Gupta, N., & Rohil, M. K. (2017). Exploring possible applications of augmented reality in education. 2017 4th International Conference on Signal Processing and Integrated Networks (SPIN). URL: https://doi.org/10.1109/spin.2017.8049989 | Perannagari, K. T., & Chakrabarti, S. (2019). Factors influencing acceptance of augmented reality in retail: insights from thematic analysis. International Journal of Retail & Distribution Management, 48(1), 18-34. URL: https://doi.org/10.1108/ijrdm-02-2019-0063 | Chen, S.-C., & Duh, H. (2018). Mixed Reality in Education: Recent Developments and Future Trends. 2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT). URL: https://doi.org/10.1109/icalt.2018.00092"
22,Chemical and Radiation Sensors for AR Devices,"Existing AR display devices do not have sensors to detect gases, radiation or other elements in the user's environment. For many use cases of interest to the oil and gas industry as well as, mining, emergency responder and chemical industries, there needs to be research into the types and integration of existing chemical sensing technologies with the AR display or wearable computing system or to develop standard interfaces with IoT sensors to display readings in real time.

This research topic is a concrete example of a more fundamental research topic: the detection of an AR system user's context beyond what can be done with existing sensors (cameras, microphone, IMU, etc). The scope of this research can be narrow or large, depending on the support provided from commercial or public agencies.

","sensors, human factors, environment, oil and gas, chemical, power and energy, radiation, hazardous materials, radioactivity, explosives, chemical hazards,, volatile organic compounds, hazardous materials, aromatic compounds, gases, hydrocarbons, indicators (chemical), radioactivity, chemical hazards, chemical detection, gas sensors","Industries, Technology","Developers, operators and employees working in places where invisible gases may pose a risk, regulatory agencies, compliance officers",#NAME?,A laboratory would need to be developed for controlled exposure to chemicals and radiation sources. The lab and platform for testing will have off-the-shelf sensors and/or the project may require development of lightweight and power efficient sensors that are effective as alternatives to cameras and existing vision-based environmental capture. The testing and development of 3D interaction modes when user's environmental sensors detect unsafe conditions is a fundamental part of this research domain.,Medium,"This topic or theme of research overlap with the topic of visualizing conditions in the direction or on the path of any moving object in atmosphere that is opaque or under water. The outcomes of this research could also be applied in non-industrial use cases (e.g., pollution sensing). The same research topic could be combined with study of user interfaces and interaction paradigms for the visually-impaired community.","In 2012, the U.S. Department of Energy Office of Scientific and Technical Information (OSTI) funded research conducted at Department of Nuclear Engineering & Radiological Sciences, University of Michigan, on this topic. Preliminary results were reported in a https://www.osti.gov/servlets/purl/1405263[poster about visualization of radiation in AR].

A https://indico.cern.ch/event/717796/contributions/2949592/attachments/1715219/2766824/PresentationGoriniSchool_MeasurementsForRobotics.pdf[2017 presentation about research on related topics conducted at CERN] using HoloLens in particle accelerator environments is also relevant.",Christine Perey,8/31/2021,1.48,"Tagami, A., & Shen, Z. (2020). LESAR: Localization System for Environmental Sensors using Augmented Reality. 2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC). URL: https://doi.org/10.1109/compsac48688.2020.00-16 | Park, Y. J., Ro, H., Byun, J.-H., & Han, T.-D. (2019). Adaptive projection augmented reality with object recognition based on deep learning. Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion. URL: https://doi.org/10.1145/3308557.3308678 | Huai, J., Zhang, Y., & Yilmaz, A. (2019). The Mobile AR Sensor Logger for Android and iOS devices. 2019 IEEE SENSORS. URL: https://doi.org/10.1109/sensors43011.2019.8956816 | Babu, N. S. C. (2017). Keynote 1: Internet of Things(IoT) and augmented reality for e-learning. 2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH). URL: https://doi.org/10.1109/eleltech.2017.8074987 | Koutitas, G., Jabez, J., Grohman, C., Radhakrishna, C., Siddaraju, V., & Jadon, S. (2018). Demo/poster abstract: XReality research lab - Augmented reality meets Internet of Things. IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). URL: https://doi.org/10.1109/infcomw.2018.8406848"
23,Reconciling Discrepancies between Documented and Actual Locations of Pipeline Networks,"Municipal water systems can be major beneficiaries of Digital Water Services: a combination of source monitoring, production and quality management, leak detection, water balance and network monitoring/modeling and process control. In order to be able to deploy these services at large scale and low cost, the first step is to create a digital representation of the pipeline network. However, documentation of pipeline networks are not always kept up-to-date, or sufficiently precise, therefore, said documentation must be validated or corrected by physical, on-site measurement and documentation.

Largely a manual process of measurement and photographic documentation, this first step represents significant time and human resource investment and is prone to errors. Head-mounted AR displays equipped with camera systems, SLAM (TOFL/LiDAR) and GPS sensors could speed up the process of documenting pipeline networks by performing volumetric capture of the exposed water network assets and interpolating the underground portions. Using the latest camera technologies on AR devices can validate geographic and dimensional data while eliminating or reducing errors.

This research explores the use of AR devices mounted with different camera and SLAM sensory systems using manual measurements as a baseline. The focus is not on end users but on the rapid and accurate capture of data about existing infrastructure.

","volumetric capture, utility asset management, digital water services, predictive water sources management, water supply, water treatment, well stimulation, well testing","Industries, Technology, Use Cases","This research will be valuable to the operators of municipal water systems, waste management systems and the IT managers, field work force, and partners performing maintenance and repairs of utilities infrastructure.","- Some AREA members build, operate and manage large public and private infrastructure for clean and waste water.
- Systemic loss in water networks ranges from 20-90% (globally). Improving the digital representation of these systems with accurate and automatic measurement technologies will reduce costs of measurement and over time, resource loss, and create a more sustainable water management system.","Initial lab testing of various volumetric capture solutions will evaluate candidate solutions, followed by in-field test comparing said solutions with physical ground truth. This will be supported by test of various data extraction methodologies.",Medium,"Leakage and issues with obstructed pipes are not unique to water utilities. The research techniques developed for this topic can be adapted for use in other types of utilities and industries where resources are sent using linear assets and infrastructure. The research platform could be commercialized into products or services to increase safety, reduce waste and optimize operations of infrastructure.","In October 2019, research about an subset of this topic https://www.researchgate.net/publication/336238139_DEVELOPMENT_OF_AUGMENTED_REALITY_PIPELINE_VISUALISER_ARPV_APPLICATION_FOR_VISUALISING_UNDERGROUND_WATER_PIPELINE[has been published in the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences].","Peter Orban, Christine Perey",8/31/2021,1.21,"Padilha, V. L., de Oliveira, F. H., Proverbs, D., & Fuchter, S. K. (2019). Innovative Applications of VR: Flash-flood control and monitoring. 2019 IEEE International Symposium on Measurement and Control in Robotics (ISMCR). URL: https://doi.org/10.1109/ismcr47492.2019.8955726 | Hossain, S. A., Islam, R., Rahman, S., & Nayeem, S. (2020). A Layered Framework for Virtual Guidance to Network Maintenance Based on Augmented Reality. IT Convergence and Security, 111-121. URL: https://doi.org/10.1007/978-981-15-9354-3_11 | Li, J., & Nguyen, C. (2019). Realtime Water-Hazard Detection and Visualisation for Autonomous Navigation and Advanced Driving Assistance. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00-27 | Koutitas, G., Jabez, J., Grohman, C., Radhakrishna, C., Siddaraju, V., & Jadon, S. (2018). Demo/poster abstract: XReality research lab - Augmented reality meets Internet of Things. IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). URL: https://doi.org/10.1109/infcomw.2018.8406848 | Szalay, M., Haja, D., Doka, J., Sonkoly, B., & Toka, L. (2019). Demo Abstract: Turning OpenStack into a Fog Orchestrator. IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). URL: https://doi.org/10.1109/infcomw.2019.8845035"
24,Visualizing Water Flow and Quality in Municipal Water Networks,"Most municipal water supply pipe networks require a manual operation of various control units in case of scheduled maintenance or an emergency. Crews operating gate valves to isolate sections of the network greatly benefit from updated information on the flow and quality of the water in these sections.

This research topic includes a field test of handheld or wearable devices to aid technicians in the field to visualize water flow and water quality data received from the control center. The user's device also could be connected to the control room, or substations, where there are multiple water pipes and sensor stations to view. The scope of the research could include the visualization of interfaces for gate valves and other equipment in the field.

","Data visualization, decision support, utility asset management, digital water services,, water supply, water treatment, well stimulation, well testing","Industries, Technology, Use Cases","This research will be valuable to the operators of municipal or regional water systems, waste management systems and the IT managers, field work force, and partners performing maintenance and repairs of utilities infrastructure.","- Some AREA members build, operate and manage large public and private infrastructure for clean and waste water. Systemic loss in water networks ranges from 20-90% (globally).
- Improving the digital representation of these systems with accurate and automatic measurement technologies will reduce loss and create a more sustainable water management system.","To model and visualize the behavior of liquid inside the pipeline, computational fluid dynamic simulations will be employed. Using areas that have reliable, manually measured flow parameters, the AR-enabled prototype system will be tested in the field. Various data extraction methodologies are used to compare the AR-assisted platforms with ground truth.",Medium,"Leakage and issues with obstructed pipes are not unique to utilities. The research techniques developed for this topic can be adapted for use in other industries where resources are sent using linear assets and infrastructure. The research platform could be commercialized into products or services to increase safety, reduce waste and optimize operations of infrastructure.",None,"Peter Orban, Christine Perey",8/31/2021,0.67,"Padilha, V. L., de Oliveira, F. H., Proverbs, D., & Fuchter, S. K. (2019). Innovative Applications of VR: Flash-flood control and monitoring. 2019 IEEE International Symposium on Measurement and Control in Robotics (ISMCR). URL: https://doi.org/10.1109/ismcr47492.2019.8955726 | Li, J., & Nguyen, C. (2019). Realtime Water-Hazard Detection and Visualisation for Autonomous Navigation and Advanced Driving Assistance. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00-27 | Castellanos, M. J., & Navarro-Newball, A. A. (2019). Prototyping an Augmented Reality Maintenance and Repairing System for a Deep Well Vertical Turbine Pump. 2019 International Conference on Electronics, Communications and Computers (CONIELECOMP). URL: https://doi.org/10.1109/conielecomp.2019.8673254 | Hossain, S. A., Islam, R., Rahman, S., & Nayeem, S. (2020). A Layered Framework for Virtual Guidance to Network Maintenance Based on Augmented Reality. IT Convergence and Security, 111-121. URL: https://doi.org/10.1007/978-981-15-9354-3_11 | Matsuura, Y., & Koizumi, N. (2018). Fairlift. ACM SIGGRAPH 2018 Emerging Technologies. URL: https://doi.org/10.1145/3214907.3214919"
25,Using 3D and World Mapping Standards to Streamline AR Experience Production,"Creating AR experiences using existing authoring environments is a time-consuming process even for highly-trained developers. One of the greatest hurdles is the specification of real world features to which AR assets are attached/anchored. An alternative to manually defining anchors for AR assets is to adapt the outputs of real world 3D capture systems used in enterprises to be used as anchors for AR.

New interfaces and data encodings for 3D capture systems to make those systems directly accessible in an AR authoring pipeline will streamline or automate the preparation of AR experiences based in part on 3D capture of enterprise environments. However, there are many different 3D capture systems. This research topic focuses on development of guidelines and/or standards that will define the formats for 3D real world mapping which can be used by commercial AR authoring platform developers and publishers.

","3D world capture, depth sensing, liDAR, AR experience authoring, AR assets, anchoring, world mapping, SLAM, simultaneous localization and mapping, standards, data preparation, object-oriented programming, open systems, authoring systems, shape recognition, feature extraction, 3d modeling","Standards, Technology","This research is relevant to AR experience developers, AR managers, AR authoring platform publishing companies, AR service providers,",#NAME?,"Requirements for this approach for authoring AR experiences will be compared with existing and new standards and/or extensions of existing standards to automate AR authoring. The gaps and requirements will more easily be provided to appropriate standards development organizations for future work. If and when new interfaces and standards are published, enterprise AR authoring software vendors will be able to use these to streamline the AR authoring pipelines in industry.",Near,"This topic could be combined with other topics to increase efficiencies in AR asset and experience authoring, management and delivery to reduce time and costs of integration with existing authoring and data management systems and platforms.",This topic was submitted for 8th and 9th AREA research projects and received high support.,Christine Perey,8/31/2021,4.13,"Cavallo, M., & Forbes, A. G. (2019). CAVE-AR: A VR Authoring System to Interactively Design, Simulate, and Debug Multi-user AR Experiences. 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2019.8798148 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089 | Babu, N. S. C. (2017). Keynote 1: Internet of Things(IoT) and augmented reality for e-learning. 2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH). URL: https://doi.org/10.1109/eleltech.2017.8074987 | Blattgerste, J., Renner, P., & Pfeiffer, T. (2019). Authorable augmented reality instructions for assistance and training in work environments. Proceedings of the 18th International Conference on Mobile and Ubiquitous Multimedia. URL: https://doi.org/10.1145/3365610.3365646 | Zigart, T., & Schlund, S. (2020). Evaluation of Augmented Reality Technologies in Manufacturing - A Literature Review. Advances in Human Factors and Systems Interaction, 75-82. URL: https://doi.org/10.1007/978-3-030-51369-6_11"
26,Automated Alert to Dangerous Workplace Conditions,"Many industries require that employees work in high risk environments. For this reason, employees are certified in advance of performing tasks and follow very strict protocols. When sensors on a device or during a work flow detect that a high risk or dangerous setting or task is imminent, there needs to be an automatically-displayed alert. Research that increases the reliability of automatic risk assessment based on situational awareness from employee-worn sensors, regardless of the technology provider, and produces a consistent and clear response regardless of the AR device model, mode or connection state would provide value to those working in high risk industries.

This research topic will extend the user experiences that are currently provided on smartphones in the workplace. It will also need to clarify when and how existing alert systems prioritize the messaging to users and test usability and benefit of having the alerts appear in AR view.

","safety, risk, automated alert, standards, situational awareness, sensors for risk detection, artificial intelligence, health risks, occupational risks, risk assessment, risk perception, accidents, safety-critical software, occupational health, occupational safety, safety, accident prevention, disaster prevention, electrical safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Standards, Technology","Standards bodies, Safety officers, employees working in high risk jobs",#NAME?,"This topic requires consensus building by working with safety officers, and new approaches to create and codify use of AI (and train the AI) to detect high risk context and circumstances, and to immediately alert the AR user. The research could also study different types of alerts for different industries, their effectiveness and recommend protocols that all devices and AR-based systems could adopt.",Near,"This topic or theme of research overlaps with the topic of visualizing alerts in a timely, intuitive and meaningful way. The outcomes of this research could also be applied in many industries. It could be combined with topics pertaining to safety and human factors.",Could be an offshoot of UL8400 or BSI IST/31.,Christine Perey,8/31/2021,0.93,"Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Aromaa, S., Väätänen, A., Aaltonen, I., Goriachev, V., Helin, K., & Karjalainen, J. (2020). Awareness of the real-world environment when using augmented reality head-mounted display. Applied Ergonomics, 88, 103145. URL: https://doi.org/10.1016/j.apergo.2020.103145 | Ko, H., Oksana, B., Na, I. S., & Pan, S. B. (2018). Analysis an identification with ECG base in augmented-reality. Proceedings of the 2018 Conference on Research in Adaptive and Convergent Systems. URL: https://doi.org/10.1145/3264746.3264802 | Aromaa, S., Väätänen, A., Kaasinen, E., Uimonen, M., & Siltanen, S. (2018). Human Factors and Ergonomics Evaluation of a Tablet Based Augmented Reality System in Maintenance Work. Proceedings of the 22nd International Academic Mindtrek Conference. URL: https://doi.org/10.1145/3275116.3275125 | MITSUHASHI, K. (2018). Suggestion of the Booting System for Necessary Safety Check by Augmented Reality and Computer Graphics. 2018 9th International Conference on Awareness Science and Technology (iCAST). URL: https://doi.org/10.1109/icawst.2018.8517244"
27,Common APIs for Tracking Libraries for Vision-based AR,"Tracking and registering the position and orientation of the user's camera in real-time is a fundamental functionality for Augmented Reality. For enterprise use cases, the environment cannot always have markers for tracking. There are vision-based tracking libraries using markers and natural feature recognition technologies available as open source libraries as well as under license from commercial sources. In the future, there will likely be many tracking libraries, each optimized for specific contexts and tasks.

When designing AR experiences, developers using existing AR authoring platforms are either forced to use the publisher's own tracking library, or, under the best of circumstances, may choose tracking libraries which will be compiled into the final experience. The developer's choice will depend on the use case requirements. However, when authoring AR experiences, the developer does not have full control or perfect knowledge (for training purposes) of all the environments and features that will be in the user camera's field of view.

As AR experiences become more complex and suitable for use in more environments and circumstances, the AR developer may need to provide (to include or offer) multiple tracking libraries, each suited to the phase of a process or the setting of the user when performing tasks.

This research topic will explore requirements of AR experiences and the attributes of common and future tracking libraries for AR and, based on use cases and requirements, develop one or more application programming interfaces that can be implemented and submitted to an appropriate organization for standardization.

","application programming interface, APIs, Tracking Library, AR Experience Software, Interoperability, Multi-Library support,, Interoperability, application programming interface (api)","Standards, Technology","Standards bodies, end users, AR experience developers, AR authoring platform publishers, AR tracking library developers, computer vision scientists and developers",#NAME?,The research will focus on tracking library characteristics and the authoring platforms. There will also need to be study of run-time systems for analyzing the real world features and matching the tracking library with the user contexts for the AR experiences to be provided. The research will also require working with open and consensus-based Standards Development processes.,Medium,"This research topic could be part of a program developing more ""fine tuned"" tracking libraries for specific enterprise workplaces, environments and tasks. The results would also benefit non-enterprise users who also change their needs and use cases without wanting to download new or update their AR experiences.",API development for more flexible architectures when authoring with or using vision-based tracking libraries was proposed as an AREA-directed research project topic in January 2020.,Christine Perey,8/31/2021,3.69,"Romli, R., Razali, A. F., Ghazali, N. H., Hanin, N. A., & Ibrahim, S. Z. (2020). Mobile Augmented Reality (AR) Marker-based for Indoor Library Navigation. IOP Conference Series: Materials Science and Engineering, 767, 012062. URL: https://doi.org/10.1088/1757-899x/767/1/012062 | Cervera-Uribe, A. A. (2017). [POSTER] The Augmented Library: An Approach for Improving Users Awareness in a Campus Library. 2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2017.22 | Cavallo, M., & Forbes, A. G. (2019). CAVE-AR: A VR Authoring System to Interactively Design, Simulate, and Debug Multi-user AR Experiences. 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2019.8798148 | Gupta, S., Chaudhary, R., Gupta, S., Kaur, A., & Mantri, A. (2019). A Survey on Tracking Techniques in Augmented Reality based Application. 2019 Fifth International Conference on Image Information Processing (ICIIP). URL: https://doi.org/10.1109/iciip47207.2019.8985779 | Joshi, Y., & Poullis, C. (2020). Portal to knowledge: a virtual library using marker-less augmented reality system for mobile devices. Optical Architectures for Displays and Sensing in Augmented, Virtual, and Mixed Reality (AR, VR, MR). URL: https://doi.org/10.1117/12.2554571"
28,Capture and Reporting of Hazardous Incidents in Augmented Reality,"In many industries, corporate, public or industry policies require documenting the circumstances of a hazardous incident and steps taken by an individual or group to reduce or eliminate risks to equipment, employees or others. In order to comply with such policies, it is valuable to have user-worn (user perspective) recording systems automatically triggered and the observations of all sensors encrypted for secure reporting. In some circumstances, a user can self-report incidents by completing an AR-enhanced report form through gestures and auditory commands which are then uploaded and recorded, possibly disseminated to appropriate functions within the organization for corrective actions (Facilities, EHS, etc.)

Alternatively, a constant recording buffer on a user device could be implemented. This could be paired with an artificial intelligence to recognize incidents and/or corrective actions. This may automatically default to an on-premise/centralized or cloud-based management system. For there to be consistent and compliant recording and reporting, AR devices could comply with a capture trigger specification, a capture and encryption protocol and, perhaps, produce reports in standard formats that are acceptable for regulatory and compliance tracing.

This research topic contributes technical requirements and potential solutions to be submitted for standardization in one or more bodies for the purpose of reducing the complexity of integrating AR-assisted automatic incident capture into the IT infrastructure of appropriate authorities.

The topic includes definition of automatic AR-assisted or enabled capture technology types suitable for hazardous incident reporting, resolutions of and compression rates for video and audio, data types to be captured (e.g., location data, temporal parameters, identities of nearby people and other), local and remote security to comply with anti-tampering precautions, and other relevant parameters, regardless of the maker of the AR display devices used.

","Standards requirements, standard specifications, hazard management, risk management, safety management, data capture, data integration, data encryption, cybersecurity, occupational risks, risk assessment, risk perception, accidents, occupational health, occupational safety, safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Standards, Technology","Standards bodies, risk managers, safety managers, policy managers, AR developers, IT developers, designers and manufacturers of enterprise AR displays would benefit from there being standards developed in this domain.",#NAME?,"The topic requires definition of requirements for automatic, real time, user-perspective, tamper-resistant capture technology that documents situations, user actions and other relevant parameters for compliance purposes. Requirements must then be codified into specifications following industry norms and consensus of group members.",Medium,"This research topic can be combined with industry-specific research projects such as the development of body-worn cameras by law enforcement officers. It can also be an extension to cybersecurity research, research about media encryption and standards pertaining to other methods of incident reporting.",Could be an offshoot of UL8400 or BSI IST/31,Christine Perey,8/31/2021,2.02,"Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089 | Abdelrazeq, A., Kohlschein, C., & Hees, F. (2019). A Cloud Based Augmented Reality Framework - Enabling User-Centered Interactive Systems Development. Advances in Intelligent Systems and Computing, 417-422. URL: https://doi.org/10.1007/978-3-030-27928-8_64 | Lebeck, K., Ruth, K., Kohno, T., & Roesner, F. (2018). Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users. 2018 IEEE Symposium on Security and Privacy (SP). URL: https://doi.org/10.1109/sp.2018.00051 | Mukhametshin, S., Makhmutova, A., & Anikin, I. (2019). Sensor Tag Detection, Tracking and Recognition for AR Application. 2019 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM). URL: https://doi.org/10.1109/icieam.2019.8743017"
29,Systems Integration between PLM Systems and AR,"Significant AR experience development effort and time is dedicated to linking domain-specific data to AR engines and presentation systems. While many industries invest in AR scene development, the need is especially high in the manufacturing industry. Product Lifecycle Management (PLM) software systems curate design, manufacturing, and sustainment information related to a product system (ideally) throughout its entire lifecycle.

Leveraging such data across PLM systems for industrial AR has mainly become a platform-specific exercise. Commercial PLM software vendors provide industrial AR solutions that leverage their application programming interfaces (APIs) to help establish AR scenes. However, most large original equipment manufacturers (OEMs) operate in complex, global, and heavily distributed supply chains. In other words, in many cases, OEMs subscribe to every major commercial PLM software platform to handle the variety of data representations provided by their suppliers. This is especially important if the developers aim to truly create a digital twin of a product or production system.

This research topic will develop and test a standard data model that permits the vendor-neutral exchange of AR-critical data to produce updatable, sustainable, and maintainable AR scenes. One particular area of interest is understanding the proper handling of industrial animations.  Though AR standards provide representations for presenting animations within AR scenes, for example, they do not directly relate to product system animations stored within PLM systems. Rather than relying on a particular PLM platform's data representations, if such a data model was successfully developed, software developers would be able to exchange data across PLM software and to platform-agnostic AR engines more readily.

","standards, data interoperability, digital twin, product lifecycle management, platform-agnostic AR solutions, application programming interfaces, distributed supply chains, manufacturing, sustainment, industrial Internet of Things, IIoT, ontologies (artificial intelligence), cost engineering, knowledge engineering, information management, project management, supply chains, team working, asset management, metadata, application programming interfaces, open source software, design engineering, systems engineering, cad/cam, quality management, supply chain management, manufacturing industries, product life cycle management, standardization, interoperability","Standards, Technology, Industries","OEM manufacturers, integrated solution and software developers, CAD/CAM providers, engineering design teams, PLM software publishers",#NAME?,This research topics could focus on testing existing PLM platforms and their AR-related competencies.  Reporting on gaps bewteen the interfaces across related software tools will be a strong contribution. Existing standard data representations provide a strong starting point for investigation. Focusing on dealing with sustainment for digital twin models would cover lots of the use cases.,Near,"OEMs with complex and heavily distributed supply chains should be a center point for the project. Program managers and technical advisors in such organizations understand the issue of cumbersome technical data packages.  This research topic significantly overlaps with https://github.com/theareaorg/AREA-Research-Agenda/blob/main/AREA_Research_Agenda_2021/Categories_and_Topics/Research_Topics/SInteroperability3-digialmodels.adoc[the Digital Model Interoperability research topic]. [BB: issue with sentence grammar] There are distinct in that this research topic is specific to the manufacturing industry. The https://github.com/theareaorg/AREA-Research-Agenda/blob/main/AREA_Research_Agenda_2021/Categories_and_Topics/Research_Topics/SInteroperability3-digialmodels.adoc[Digital Model Interoperability research topic] relates more generally to 3D asset translation and can be applied to other domains, such as construction.","There exist resources to help position research efforts.  For example, the https://www.cax-if.org/[CAx Implementor Forum] provides a number of test cases. The Khronos Group is continously updating https://www.khronos.org/gltf/[glTF], the latest de-facto standard for lightweight model presentation. https://www.asme.org/topics-resources/content/y14-standards-overview[ASME Y14] is a working group that focuses on the standard presentaiton of GD&T annotations.",Bill Bernstein,8/31/2021,2.89,"Eckertz, D., Berssenbrügge, J., Anacker, H., & Dumitrescu, R. (2019). Work-in-Progress: Enhancing Collaboration Using Augmented Reality Design Reviews for Product Validation on the Example of Additive Manufacturing. Cyber-Physical Systems and Digital Twins, 244-254. URL: https://doi.org/10.1007/978-3-030-23162-0_22 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089 | Kuster, T., Stocklein, J., Roltgen, D., Trinoga, M., Masuch, N., Fahndrich, J., ... Schmid, F. (2019). A Distributed Architecture for Modular and Dynamic Augmented Reality Processes. 2019 IEEE 17th International Conference on Industrial Informatics (INDIN). URL: https://doi.org/10.1109/indin41052.2019.8972101 | Bellalouna, F. (2020). Industrial Use Cases for Augmented Reality Application. 2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom). URL: https://doi.org/10.1109/coginfocom50765.2020.9237882 | Zigart, T., & Schlund, S. (2020). Evaluation of Augmented Reality Technologies in Manufacturing - A Literature Review. Advances in Human Factors and Systems Interaction, 75-82. URL: https://doi.org/10.1007/978-3-030-51369-6_11"
30,Harmonization of Standard Industrial Data with Lightweight 3D Models,"Computer-aided design (CAD) platforms provide a broad suite of tools for constructing highly precise digital three-dimensional (3D) representations of parts, assemblies, and structures. Many engineering teams and organizations adhere to a single CAD platform for formally representing geometric dimensioning and tolerancing (GD&T) requirements, optimizing design performance through detailed simulations, and developing initial process plans for manufacturing the parts. With the increasing emphasis on model-based engineering across industry, more value is embedded in these digital models every day.

To allow for native 3D models to be displayed on AR modalities, model translation is necessary into more efficient digital models.  Previous work has focused on model tessellation and decimation to make sure that the models are perceptually accurate. Inherently, there is a loss in geometry and topology precision in the translation process.  However, for most AR use cases, there is no need for such a high level of accuracy in the presentation of part and assembly geometries. These translation methods do not currently port supporting information, such as GD&T and other Product Manufacturing Information (PMI), in a platform-agnostic manner.

There is a research opportunity for leveraging existing industrial data standards that enable the exchange of part and assembly information with limited loss of information.  One particular use case of interest is dealing with engineering change management.  In theory, model-based engineering facilitates better management of engineering change, as the native CAD model serves as a reference for all product lifecycle functions and processes.  Let's consider assembly animations and their use in a AR-assisted assembly workstation.  If there is a persistent link or pipeline between the native 3D models and animation with the tessellated model to be used in XR, theoretically, the AR-assisted workstation could be agile and updatable based on upstream engineering changes.

Additional work is required in fundamental mappings between standard data representations, both from the domain perspective such as manufacturing and the AR standard community such as glTF animations.  In general, such work has been characterized as standards harmonization.

","digital enterprise, model translation, interoperability, product manufacturing information, geometric dimensioning and tolerancing, assembly animation, engineering change management, updatable AR, maintainable AR, transferrable AR, agile AR, knowledge representation, ontologies (artificial intelligence), information management, production planning, metadata, application programming interfaces, systems engineering, cad/cam, cad, computer aided design, integration, industry 4.0, 3d modeling, assembly, manufacturing data processing, product life cycle management, computer aided engineering, Interoperability, standardization, protocols","Standards, Technology, Industries","OEM manufacturers, integrated solution and software developers, CAD/CAM providers, engineering design teams","- Translations of 3D models consumes significant time and resources.
- If better tools existed for translating native models into AR-ready representations, industrial end-users would benefit directly.
- The strong design and manufacturing focus of the AREA sit at the center of this potential research area's benefits.",Existing model translators and standard data representations provide a strong starting point for investigation. Focusing on handling PMI and properly spatially anchoring them in the tessellated model would be a good choice for an initial project.,Near,"This topic would directly benefit construction and manufacturing industries.  Luckily, lots of the existing domain-specific standards cut across these two industries. Working together to develop application domain extensions for AR standards would be a good first step.  This research topic significantly overlaps with https://github.com/theareaorg/AREA-Research-Agenda/blob/main/AREA_Research_Agenda_2021/Categories_and_Topics/Research_Topics/BIntegration3-ar2plm.adoc[the AR to PLM research topic].  There are distinct in that this research topic is specific to the manufacturing industry.  The other research topic relates to developing a standard data model for ingesting PLM data, such as sustainment data for maintaining digital twins.","There exist resources to help position research efforts.  For example, the https://www.cax-if.org/[CAx Implementor Forum] provides a number of test cases. The Khronos Group is continously updating https://www.khronos.org/gltf/[glTF], the latest de-facto standard for lightweight model presentation. https://www.asme.org/topics-resources/content/y14-standards-overview[ASME Y14] is a working group that focuses on the standard presentaiton of GD&T annotations.",Bill Bernstein,8/31/2021,2.2,"Fradi, A., Louhichi, B., Mahjoub, M. A., & Eynard, B. (2017). 3D Object Retrieval Based on Similarity Calculation in 3D Computer Aided Design Systems. 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications (AICCSA). URL: https://doi.org/10.1109/aiccsa.2017.101 | Xia, L., Lu, J., Zhang, Z., Chen, R., Wang, S., & Zhang, H. (2019). Development and Application of Parts Assembly Guidance System Based on Augmented Reality. 2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC). URL: https://doi.org/10.1109/iaeac47372.2019.8997861 | Khedwala, M., Momin, F., Pachhapure, U., & Shaikh, S. (2018). Analysis of Auto Generation of 3D Model Using Multiple 2D Graphics to Manifest Through Augmented Reality. 2018 International Conference on Smart City and Emerging Technology (ICSCET). URL: https://doi.org/10.1109/icscet.2018.8537310 | Hayashida, H., Funashima, H., Katayama-Yoshida, H., & Nomakuchi, T. (2017). Opening the Door for the New Methodology for Optimizing Functional Material Development in Technology Management Framework II. 2017 Portland International Conference on Management of Engineering and Technology (PICMET). URL: https://doi.org/10.23919/picmet.2017.8125242 | Thies, L., Strohmeyer, C., Ebert, J., Stamminger, M., & Bauer, F. (2019). Compiling VR/AR Trainings from Business Process Models. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00-51"
31,Testing Protocols for AR-assisted Human-Robot Interaction,"In terms of collaborative robotics, the widespread adoption of robots in historically manual manufacturing environments (which are subject to high product turnover, short production runs, and high variability in equipment configurations) is limited by the robotsÃ¢ÂÂ inability to effectively and safely integrate and interact with the existing human labor.  Instead, so-called collaborative robots are relegated to secluded operations with minimal contact with the workforce.  The robotsÃ¢ÂÂ inability to communicate with, understand the intention of, and establish a mutual understanding of the environment and situation with human coworkers decreases the robotsÃ¢ÂÂ usefulness in collaborative teams consisting of both robots and people.  This limitation is driven by both the absence of tools and protocols needed for effectively describing and measuring human-robot interactions, an incomplete collection of metrics for assessing human-robot teaming performance, and insufficient protocols for enabling more intuitive interfacing with robotic tools. These challenges are compoudned when augmented reality technologies are used at the interface between the robotics and human workers.

This research topic focuses on providing the methods, protocols, and metrics necessary to evaluate the interactive and teaming capabilities of robot systems. It uses a task-driven decomposition of manufacturing processes to assess and assure the safety and effectiveness of human-robot collaborative teams.

","robotics, human-robot interaction, human-computer interaction, remote monitoring, remote control, collaborative robots, autonomous agents, communication, computer vision, control systems, cooperative systems, grippers, human factors, human-robot interaction, industrial robots,	industry 4.0, intelligent robots, multi-robot systems, occupational safety, robotics, safety","Standards, Technology, End User and User Experience",Manufacturers will benefit from the products generated as a result from this research project.  Robotics providers can also benefit in that standard testing protocols for human-robot interaction will generate new sales tactics. End users will benefit in that the end state will be much safer in complex manufacturing environments.,#NAME?,"This collection of methods, protocols, and metrics will enable integrators and end-users to maximize the effectiveness and efficiency of collaborative human-robot teams in production processes, impacting both large-scale companies designing and repurposing hybrid manufacturing workflows, and smaller companies looking to begin introducing automated tools into manual processes.",Long,"This research topic mirrors https://www.nist.gov/programs-projects/performance-human-robot-interaction[an existing project at NIST]. Inspiration can be driven from the existing work generated by that team. Furthermore, IEEE is a leader in curating academic work in this area. Refer to https://www.ieee-ras.org/conferences-workshops[IEEE RAS] for related publication venues, including https://www.ieee-ras.org/conferences-workshops/fully-sponsored/case[IEEE CASE], https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra[IEEE ICRA], and https://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros[IEEE IROS].","This topic requires significant hardware, middleware, and software integration. One open source framework is https://rosindustrial.org/[ROS-Industrial]",Bill Bernstein,8/31/2021,1.16,"Muhammad, F., Hassan, A., Cleaver, A., & Sinapov, J. (2019). Creating a Shared Reality with Robots. 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI). URL: https://doi.org/10.1109/hri.2019.8673191 | Jost, J., Kirks, T., Gupta, P., Lunsch, D., & Stenzel, J. (2018). Safe Human-Robot-Interaction in Highly Flexible Warehouses using Augmented Reality and Heterogenous Fleet Management System. 2018 IEEE International Conference on Intelligence and Safety for Robotics (ISR). URL: https://doi.org/10.1109/iisr.2018.8535808 | Bolano, G., Juelg, C., Roennau, A., & Dillmann, R. (2019). Transparent Robot Behavior Using Augmented Reality in Close Human-Robot Interaction. 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN). URL: https://doi.org/10.1109/ro-man46459.2019.8956296 | Whitsell, B., & Artemiadis, P. (2017). Physical Human-Robot Interaction (pHRI) in 6 DOF With Asymmetric Cooperation. IEEE Access, 5, 10834-10845. URL: https://doi.org/10.1109/access.2017.2708658 | Xue, C., Qiao, Y., & Murray, N. (2020). Enabling Human-Robot-Interaction for Remote Robotic Operation via Augmented Reality. 2020 IEEE 21st International Symposium on ""A World of Wireless, Mobile and Multimedia Networks"" (WoWMoM). URL: https://doi.org/10.1109/wowmom49955.2020.00046"
32,Trade-off and Substitution: Stereoscopic Vision for Spatial Audio,"Stereoscopic vision has long been considered the best type of visualization in terms of matching physical and simulated realities. While stereoscopic vision is the goal, producing a perfect 3D visualization and registration of AR assets is difficult using current technologies. Addressing the shortcomings of current AR displays will be prohibitively high and present a financial barrier to AR adoption in enterprises.

Leveraging advancements in Digital Signal Processing (DSP) and audiology, a new class of devices are emerging. Spatially-aware audio transducers can help determine the exact position and posture/pose of the wearer as well as generate a simulated sound field that matches the physical environment. Such systems could be combined with existing vision-centric displays for high fidelity enterprise AR experiences.

The scope of this topic includes measurement of the spatial audio technology resource requirements and impacts of combining visual cues with spatial audio on user performance. Comparative studies of human cognitive performance aided by varying blends of spatial technology ranging from Ã¢ÂÂaudio-onlyÃ¢ÂÂ to Ã¢ÂÂvideo-onlyÃ¢ÂÂ and various combinations of both are also in scope.

","spatial audio, effectiveness, spatial vision, 3D audio, perception, audio signal processing, acoustic waves, active noise control","Technology, End User and User Experience, Displays","AR experience designers, developers of integrated sensor and world capture components, human factors researchers","Spatial vision is not always as practical, comfortable or affordable way to produce AR experiences that help reach use case objectives.
- If performance requirements on vision-based AR delivery can be reduced using spatial audio components or solutions, enterprises may have more options and greater flexibility when sourcing their AR experience delivery devices.
- Adopting spatial audio-based solutions may lower total resourcing needs, reducing the financial barriers of enterprise adoption.
- Spatial audio may also increase the impact of AR experiences in which there is possibility of visual AR interference or occlusion of the user's vision.","This research topic will require development of visual and audio AR experiences to be produced in a highly controlled laboratory environment within which a series of experiments can be conducted and reproduced. Studies will compare spatial audio requirements to vision-only AR experiences on the basis of accuracy, speed, battery life, bandwidth requirements, processor performance, wearer comfort and pricing. In addition to user perception assessments through surveys and interviews, methods could be expanded to include time-motion studies using standardized, public and well-documented processes typical of industry verticals, use cases and horizontal use case categories.",Medium,"This topic is at the intersection of both 3D visualization and 3D audio. The methodologies and tools developed for this research could be used in the study of perception, presence, and lead to new guidelines for AR developers and manufacturers of HMDs for enterprise AR.","In 2016, the Sound of Vision consortium, which focuses on the construction of a new prototype electronic travel aids for the blind https://www.researchgate.net/publication/304822071_Sound_of_Vision_-_Spatial_Audio_Output_and_Sonification_Approaches[published a report] about audio-assisted vision.

A peer-reviewed article http://www.aes.org/e-lib/browse.cfm?elib=15891[presenting a novel technique for reproducing coherent audio visual images for multiple users], only wearing 3D glasses and without utilizing head tracking was published in 2011 in the Journal of The Audio Engineering Society.","Peter Orban, Christine Perey",8/31/2021,3.33,"Kim, H., Remaggi, L., Jackson, P. J. B., & Hilton, A. (2019). Immersive Spatial Audio Reproduction for VR/AR Using Room Acoustic Modelling from 360° Images. 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2019.8798247 | Heller, F., & Schöning, J. (2018). NavigaTone. Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. URL: https://doi.org/10.1145/3173574.3174211 | Schmalstieg, D. (2018). VIS Keynote Address : When Visualization Met Augmented Reality. 2018 IEEE Conference on Visual Analytics Science and Technology (VAST). URL: https://doi.org/10.1109/vast.2018.8802427 | Erkut, C., Holfelt, J., & Serafin, S. (2018). Mobile AR In and Out: Towards Delay-Based Modeling of Acoustic Scenes. 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). URL: https://doi.org/10.1109/vr.2018.8446230 | Abdelrazeq, A., Kohlschein, C., & Hees, F. (2019). A Cloud Based Augmented Reality Framework - Enabling User-Centered Interactive Systems Development. Advances in Intelligent Systems and Computing, 417-422. URL: https://doi.org/10.1007/978-3-030-27928-8_64"
33,Biometric Identification of Wearable Enterprise AR Device Users,"New AR display devices encounter significant resistance from enterprise IT teams who consider the new hardware platforms increase security threats, consequently, increasing the need for an elevated security posture.

Driven by a human-centric approach, a critical step in ensuring compliance with existing security policies and systems is to balance the security with accurate and rapid user authentication and ultra-low-friction user input.

Biometric identification methods, ranging from palm-prints, voice-prints, iris scanning, gait to heartbeat detection offer a plethora of opportunities for identification of wearable enterprise AR device users before providing access to enterprise work orders and data.

This research topic compares different modalities of biometric identification and classifies them based on accuracy, cost and ease-of-use.

","biometric, palm print, voice print, gait, retina scanning, iris scanning, heartbeat detection, skin conductivity, access control, data protection, security systems, authentication, message authentication, authorization, data security, access protocols","Displays, End User and User Experience, Technology","All stakeholder in corporate security organizations but primarily CISOs, CIOs, IT and security managers. On the vendor side, OEMs, solutions providers, system integrators and independent software vendors will be impacted by this research.",#NAME?,"This research will require rigorous laboratory tests, deployed via multiple cells of different modalities. This will be followed by human factors and security research, culminating in field trials. Once baselines are available and validated, best practices can be established.",Medium,"This topic is closely related to another proposed AREA Research Agenda topic on cleaning and authenticating multi-user devices end user [ra-Tsecurity5-multiuserdisplays]. The topics could be combined with other AR security topics to develop a broader research program. In addition, the topic could be expanded to use the sensors on devices of other AR users in a workplace to confirm user identities.",The field of biometric authentication in cybersecurity is vast and there are many highly reputable research centers that could contribute to this research. Hundreds of publications appear each year in journals and proceedings. https://www.heinz.cmu.edu/~acquisti/papers/AcquistiGrossStutzman-JPC-2014.pdf[This paper describes results of studies to connect AR users with sensitive personal information derived from on-line platforms and use of these data to predict AR user interests and preferences.] In the https://dl.acm.org/doi/proceedings/10.1145/3457339[proceedings of the 7th ACM on Cyber-Physical System Security Workshop] (May 2021) https://dl.acm.org/doi/pdf/10.1145/3457339.3457983[an article compiles recently published work on this topic and describes MoveAR.] The goal of MoveAR is to distinguish between a legitimate user and potential adversaries based on the signatures detected by the on-device sensors as the user interacts with an augmented reality environment.,Peter Orban,8/31/2021,1.58,"Garae, J., Ko, R. K. L., Kho, J., Suwadi, S., Will, M. A., & Apperley, M. (2017). Visualizing the New Zealand Cyber Security Challenge for Attack Behaviors. 2017 IEEE Trustcom/BigDataSE/ICESS. URL: https://doi.org/10.1109/trustcom/bigdatase/icess.2017.362 | Lebeck, K., Ruth, K., Kohno, T., & Roesner, F. (2018). Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users. 2018 IEEE Symposium on Security and Privacy (SP). URL: https://doi.org/10.1109/sp.2018.00051 | Wazir, W., Khattak, H. A., Almogren, A., Khan, M. A., & Ud Din, I. (2020). Doodle-Based Authentication Technique Using Augmented Reality. IEEE Access, 8, 4022-4034. URL: https://doi.org/10.1109/access.2019.2963543 | Epstein, J. (2017). An NSF View of Multimedia Privacy and Security. Proceedings of the 2017 on Multimedia Privacy and Security. URL: https://doi.org/10.1145/3137616.3137622 | Shen, Y., Wen, H., Luo, C., Xu, W., Zhang, T., Hu, W., & Rus, D. (2019). GaitLock: Protect Virtual and Augmented Reality Headsets Using Gait. IEEE Transactions on Dependable and Secure Computing, 16(3), 484-497. URL: https://doi.org/10.1109/tdsc.2018.2800048"
34,Authoritative Information and Source Validation in AR,"In many use cases and network architectures, data requested by and provided to an AR user for an experience is not pre-loaded on the users device. For a variety of reasons and through a range of technologies, information is streaming from the cloud or edge to the AR device in real time. The reverse is also happening. Sensors on an AR user's device are capturing the real world and can send during or after world capture salient features or any combination of data (e.g., point clouds, video, audio, etc) to a safe and high capacity storage resource in the cloud or on the edge. Users may also need to use an AR device to annotate, confirm ground truth or add information about the real world to the cloud-based databases. During data creation (annotation) or transfer, there may be opportunities for agents to insert inaccurate or false information, or for corruption.

Depending on use cases or publishers, the level of confidence about accuracy and authorship of information consumed from or added to a remote source will vary. In enterprise or industrial use cases, details about asset authenticity, ownership or conditions for use must be associated with the AR asset in metadata.

This research topic focuses on development of ontologies, protocols and/or standards to ensure and to  communicate to or between enterprise systems and users in workplaces that data delivered for use in AR experiences is from an authorized source. In parallel, the research will study or develop on-device authentication systems to validate that data which is added to a pooled (cloud-based) data repository during an AR experience (e.g. tagging information and placing information) is authoritative and the source traceable.

","data capture, data streaming, security, authentication, author, authorship, publication, ownership, remote data repositories, AR cloud, edge computing, spatial computing, access control, data protection, security systems,  authentication, message authentication, authorization, data security, access protocols",Technology,"Network operators, network managers, enterprise IT managers, AR experience publishers, AR experience authoring platforms, AR developers","- Before introducing data from remote sources to users in their networks or from users' AR devices into their data management systems, AREA member organizations must ensure that the data source is authenticated and any metadata associated with it can be used regardless of the choice of display or data architectures.
- The members need to better understand the potential risks and opportunities of introducing AR Cloud for real world capture and data delivery in enterprise networks.",The research will focus on device encoding and edge computing technologies from multiple suppliers that can support distributed AR architectures. Studies will evaluate use of encryption and authentication technologies on device for suitability in distributed computing. Laboratory-based studies in controlled environments will measure and compare different approaches to data authentication and metadata authoring.,Medium,"This research topic could be part of a program studying the potential benefits of AR Cloud and 5G networks which provide low-latency and high bandwidth connectivity between cloud, edge and AR devices. Other topics such as cloud-based rendering of 3D graphics, discovery of AR experiences and security could be combined with this topic.","There is work in the W3C, IETF, IEEE, OMG and other standards bodies on related topics that could contribute to development of best practices and standards for enterprise data management systems.",Christine Perey,8/31/2021,4.7,"Bermejo, C., Huang, Z., Braud, T., & Hui, P. (2017). When Augmented Reality meets Big Data. 2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW). URL: https://doi.org/10.1109/icdcsw.2017.62 | Singh, S. (2017). Optimize cloud computations using edge computing. 2017 International Conference on Big Data, IoT and Data Science (BID). URL: https://doi.org/10.1109/bid.2017.8336572 | Ramaseri Chandra, A. N., El Jamiy, F., & Reza, H. (2019). Augmented Reality for Big Data Visualization: A Review. 2019 International Conference on Computational Science and Computational Intelligence (CSCI). URL: https://doi.org/10.1109/csci49370.2019.00238 | Lebeck, K., Ruth, K., Kohno, T., & Roesner, F. (2018). Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users. 2018 IEEE Symposium on Security and Privacy (SP). URL: https://doi.org/10.1109/sp.2018.00051 | Khurshid, A., Cleger, S., & Grunitzki, R. (2020). A Scene Classification Approach for Augmented Reality Devices. Lecture Notes in Computer Science, 164-177. URL: https://doi.org/10.1007/978-3-030-59990-4_14"
35,Automatic Detection and Obfuscation of Facial and/or Personal Data of People in AR User Vicinity,"In or in proximity of an AR-enabled user's workplace, and in the field of view of the AR display's camera, there may be people who have not agreed to (or are not able to grant permission for) their facial features or any personal data to be included in the AR system's live video stream. If the private information of a person is captured without their explicit permission, a company may be held responsible for storing and any future use of the data. To reduce potential liabilities, entities responsible for a workplace will seek to implement a component of an AR display that removes all unrecognized faces from their systems.

This research topic includes using automatic detection of faces in an AR camera's field of view, determining if the detected facial features are among those of people who have granted their permission to be tracked, and if the face does not match any in the database of those who have granted permission, to automatically and continuously obfuscate the features.

","face detection, facial identification, obfuscation of region of interest, personal information, privacy, privacy protection, security, compliance, biometrics, data security, access protocols","Technology, End User and User Experience, Business","All stakeholders in corporate security organizations including but not limited to privacy managers, workplace policy managers and risk managers. In order for obfuscation to be implemented in commercial systems, the research would need to take into account the requirements of the AR display ecosystem players (e.g., OEMs, solutions providers, system integrators and independent software vendors) who could leverage the results.","- Employees of AREA member companies may use their AR-enabled systems, including cameras and microphones, in public spaces or in the presence of customers, employees of partner organizations or elsewhere that are not in their exclusive control.
- If an employee is using an AR device in the presence of people who have not granted permission for their personal information, including but not limited to facial features, to be stored and used by the company, the company may be exposed to penalties for breaching privacy data protection regulations.
- Technology components that remove or reduce this type of risk will increase compliance without the user's needing to take action or interrupt the processes they are following to perform a task.","The research will identify and evaluate automatic facial detection and identification technologies for suitability on an AR display. This may include assessment of speed, reliability and computational complexity. Computer vision solutions that meet requirements will need to be compared and tested to ensure that they do not reduce display performance or ability to meet the requirements of the user's primary AR use cases.

This topic may also involve introducing systems that interrupt an AR-assisted process and prompt a user to change orientations and/or ask unauthorized people to move out of camera view.",Medium,"This topic can be combined with the study of automatic detection and management of other sensitive data types. For example, the license plates of cars, names of people appearing in semi-public places (e.g. postal box), and voices of people in proximity of the AR-enabled user could be selectively removed based on the local regulations and privacy policies. It could also be combined with the research [ra-Tauthentication5-biometric][on biometric authentication for AR display users].",A 2014 peer-reviewed paper https://www.researchgate.net/publication/323372332_Face_Recognition_and_Privacy_in_the_Age_of_Augmented_Reality[describes tests performed and highlights the implications of the convergence of face recognition technology and use of AR].,Christine Perey,8/31/2021,3.34,"Knierim, P., Wo?niak, P. W., Abdelrahman, Y., & Schmidt, A. (2019). Exploring the Potential of Augmented Reality in Domestic Environments. Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services. URL: https://doi.org/10.1145/3338286.3340142 | Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Lebeck, K., Ruth, K., Kohno, T., & Roesner, F. (2018). Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users. 2018 IEEE Symposium on Security and Privacy (SP). URL: https://doi.org/10.1109/sp.2018.00051 | Darwish, S. M., Mohallel, A. A., & Emara, D. (2018). An Enhanced Registration and Display Algorithm for Medical Augmented Reality. 2018 14th International Computer Engineering Conference (ICENCO). URL: https://doi.org/10.1109/icenco.2018.8636139 | Abdelrazeq, A., Kohlschein, C., & Hees, F. (2019). A Cloud Based Augmented Reality Framework - Enabling User-Centered Interactive Systems Development. Advances in Intelligent Systems and Computing, 417-422. URL: https://doi.org/10.1007/978-3-030-27928-8_64"
36,Cybersecurity Risk Assessment and Reduction for AR Environments,"Sensitive enterprise or customer data could be exposed to threats from hostile actors when in field of view of AR-enabled cameras, and/or when sent to users' AR device in order to support their task performance. The hostile actors may interfere with transmission of sensitive data, interrupt or distort its presentation to the user in the AR display, or could operate without detection while ""scraping"" enterprise or customer data for other users. Cybersecurity threat identification and assessment, and mitigation measures for those managing the AR displays in a company are critical to integration of AR in mission critical environments and need to be studied.

Approaches to reducing risk and increasing resilience of AR display devices can be tested and industry guidelines and best practices published by and for cybersecurity experts. The scope of the research could include comparisons of device vs wireless network security.

","Cybersecurity, risk, encryption, distributed ledger technologies, integration, data interception, network security, security of data, computer crime, computer network security, computer privacy, cryptographic protocols, fraud, intrusion detection, data protection, blockchain, access control","Technology, Business","Data security officers, employees working in highly sensitive disciplines, customer data protection, employees using AR in the field to access secure databases,",#NAME?,"This project will require laboratory or bench studies with cybersecurity threats into commercial wearable AR displays will highlight vulnerabilities. Tests of commercial or experimental software to manage sensitive data can be conducted in simulated environments. Further, after the tests in simulation, there should be research on the use of the threat mitigation systems in live environments.",Medium,"This topic or theme of research can be combined with assessments of geofencing, biomarkers for user authentication and other methods to reduce risks to enterprise data.","In 2017, this topic was the focus of the first AREA-directed research project. The AREA published the first report on the topic of security for wearable AR displays to members in June 2017 and released the report and assessment protocol to the ecosystem in mid-2019.",Christine Perey,8/31/2021,2.4,"Bermejo, C., Huang, Z., Braud, T., & Hui, P. (2017). When Augmented Reality meets Big Data. 2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW). URL: https://doi.org/10.1109/icdcsw.2017.62 | Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Lebeck, K., Ruth, K., Kohno, T., & Roesner, F. (2018). Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users. 2018 IEEE Symposium on Security and Privacy (SP). URL: https://doi.org/10.1109/sp.2018.00051 | Ramaseri Chandra, A. N., El Jamiy, F., & Reza, H. (2019). Augmented Reality for Big Data Visualization: A Review. 2019 International Conference on Computational Science and Computational Intelligence (CSCI). URL: https://doi.org/10.1109/csci49370.2019.00238 | Hirve, S. A., Kunjir, A., Shaikh, B., & Shah, K. (2017). An approach towards data visualization based on AR principles. 2017 International Conference on Big Data Analytics and Computational Intelligence (ICBDAC). URL: https://doi.org/10.1109/icbdaci.2017.8070822"
37,Impact of AR Delivery in Human-Supported Operational Risk Mitigation,"Whilst automation continues to bring efficiency to operational processes and practices and IoT data capabilities increase exponentially, a crucial element around human intervention remains unaddressed. Specifically, as incoming data indicates that an operational process is trending upward or downward and is approaching deviation from set thresholds, are the humans in proximity to this equipment aware and can they proactively take decisions around appropriate actions, consulting additional support human support and/or schematics, flow charts, or other assets, where necessary? In 2018, McKinsey published an informative report on skill shifts, automation, and the future of the workforce, indicating that, while hours spent performing physical, manual, and basic cognitive skills would decrease by 14-15% between the years 2016 and 2030, higher cognitive skills, social and emotional skills, and technological skills would increase by 8, 24, and 55% respectively. This indicates a sharp departure from manual physical intervention and a transition to interaction between environmental data, people, and equipment in nuanced ways that involve rational analysis and resulting action. +

Increasingly, industries are collecting mass amounts of operational data and parameters via IoT dashboards, though there is little guidance that enables the operator of the future to interpret this data and take appropriate action proactively. Deloitte's 2020 Global Human Capital Trends report indicated that high performance organizations are Ã¢ÂÂevolving from a focus on automating work to replace workers, to augmenting workers with technology to create superjobs, to collaborating with technology to form superteamsÃ¢ÂÂ. AR is specifically and ideally positioned to play a large role in this transition process for organizations across the globe.

This study would aim to specifically measure the tangible operational processes proactively improved by human intervention to a process prompted by a connected AR headset, providing data insights, as well as prompting appropriate proactive human behavior to maintain operational parameters/limits. +

","Automation, resklling, skill development, augmentation, superjobs, superteams, operational excellence, IoT, process improvement, augmented reality, augmented reality, failure, indicators, just in time, mixed realities, optimization","Business, End User and User Experience, Use Cases, Displays","Operational excellence professionals, chief operating officers, board of directors, safety and risk professionals","- Automation introduces new workforce compositions and behaviors. In order to adapt, organizations will need to deploy AR for humans in the workforce that encourages higher-level cognitive processes and decision making, in partnership with automated technology and data at the worksite.
- As data analysis and technological literacy varies greatly among operational workforces globally, some degree of intervention and support will be necessary to ensure that productivity and safety targets are achieved in a new age of work.
- AR is uniquely positioned to deliver guidance and to develop workforce skills in the ""flow of work"", as it does not require hand-held or mounted displays that compromise safety and efficiency by directing human hands and eyes away from the production cycle itself.+","The proposed research would need to identify operational processes for which operational parameters/thresholds have been defined and IoT data is available. Research would include current % of time operational process performs outside of appropriate limits/thresholds and introduction of AR data presentation, analysis, and intervention via A/B trial scenarios, potentially with a few different levels of AR intervention. Observe post-intervention data. Post-study operational process optimization time could be calculated and recommendations developed for future implementation.",Near,"This study could be combined with existing research programs associated with metals and mining, oil and gas, aerospace, manufacturing, and operational excellence in general.","There are valuable references related to automation and necessary upskilling contained in https://www.mckinsey.com/featured-insights/future-of-work/skill-shift-automation-and-the-future-of-the-workforce[this report published by McKinsey.] https://www2.deloitte.com/us/en/insights/focus/technology-and-the-future-of-work/reskilling-the-workforce.html[This report published by Deloitte] focuses on guidance and learning ""in the flow of work.""",Jennifer Rogers,8/31/2021,1.6,"Cavallo, M., Dolakia, M., Havlena, M., Ocheltree, K., & Podlaseck, M. (2019). Immersive Insights: A Hybrid Analytics System forCollaborative Exploratory Data Analysis. 25th ACM Symposium on Virtual Reality Software and Technology. URL: https://doi.org/10.1145/3359996.3364242 | Bermejo, C., Huang, Z., Braud, T., & Hui, P. (2017). When Augmented Reality meets Big Data. 2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW). URL: https://doi.org/10.1109/icdcsw.2017.62 | Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Marques, B., Santos, B. S., Araujo, T., Martins, N. C., Alves, J. B., & Dias, P. (2019). Situated Visualization in The Decision Process Through Augmented Reality. 2019 23rd International Conference Information Visualisation (IV). URL: https://doi.org/10.1109/iv.2019.00012 | Chmielewski, M., Kukielka, M., Gutowski, T., & Pieczonka, P. (2019). Handheld combat support tools utilising IoT technologies and data fusion algorithms as reconnaissance and surveillance platforms. 2019 IEEE 5th World Forum on Internet of Things (WF-IoT). URL: https://doi.org/10.1109/wf-iot.2019.8767263"
38,Opportunities for AR Cloud Technologies in Enterprise,"AR Cloud technologies are emerging as part of a broader, 3D Ã¢ÂÂspatial computingÃ¢ÂÂ trend. Accurate three-dimensional and spatially-anchored models of the real world are being captured using AR devices and proposed for the design of AR-enabled services with high fidelity positioning of users and assets to automatically connect workers with data from enterprise management systems. Proponents of AR Cloud architectures suggest that using these distributed technologies will result in lower total cost of ownership, higher performance and more flexible AR-enabled solutions. With spatial computing, AR users will have higher engagement, seamless collaborative experiences while sharing 3D models, and options for separating static from dynamic parts of the physical world in AR authoring. By securely off-load computational complexity of AR processes to the edge of their networks, AR display devices will be lighter, have lower power requirements and, potentially lower costs.

This research project will focus on definition of requirements and development of prototypes of devices and network technologies that are not tied to any single vendor's device and network offerings. The results will permit enterprises to evaluate and quantify the benefits of distributed AR Cloud architectures without limiting options for multi-vendor networks. Edge computing technologies will also be essential components.

","edge computing, spatial computing, AR cloud, cloud computing, 3D mapping, computer vision, object tracking, localization, relocalization, edge computing, cloud computing, distributed computing, network architecture",Technology,"Network operators, network managers, enterprise IT managers, AR display designers, AR display manufacturers, AR experience authoring platforms, AR developers","- Before introducing new architectures in their networks, AREA member organizations must understand the potential benefits and ensure that they are not locked into one vendor's vertically-integrated technology silo.
- AREA members need to better understand the potential risks and opportunities of introducing AR Cloud in enterprise networks.
- In addition, AREA members seek research that will develop practical guidelines and permit them to keep up with and evaluate this trend over the coming months and years.","The research will focus on edge computing technologies from multiple suppliers that can support distributed AR architectures. Studies will compare the components of AR experience delivery that are suited to distributed computing. Laboratory-based studies in controlled environments will measure performance characteristics across different scenarios. There will also need to be study of network-based storage of world maps and the use of these 3d models for real-time object identification, device and object tracking, and localization of devices and objects. End user satisfaction studies can also be used for this research.",Medium,"This research topic could be part of a program studying the potential benefits of 5G networks which provide low-latency and high bandwidth connectivity. Other topics such as cloud-based rendering of 3D graphics, discovery of AR experiences and security could be combined with this topic.",The study and testing of AR cloud technologies in enterprise use cases and networks was proposed as an AREA-directed research project topic in January 2021.,Christine Perey,8/31/2021,5,"Liu, Q., Huang, S., & Han, T. (2017). Fast and accurate object analysis at the edge for mobile augmented reality. Proceedings of the Second ACM/IEEE Symposium on Edge Computing. URL: https://doi.org/10.1145/3132211.3132458 | Schneider, M., Rambach, J., & Stricker, D. (2017). Augmented reality based on edge computing using the example of remote live support. 2017 IEEE International Conference on Industrial Technology (ICIT). URL: https://doi.org/10.1109/icit.2017.7915547 | Qiao, X., Ren, P., Dustdar, S., & Chen, J. (2018). A New Era for Web AR with Mobile Edge Computing. IEEE Internet Computing, 22(4), 46-55. URL: https://doi.org/10.1109/mic.2018.043051464 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089 | Hossain, S. A., Islam, R., Rahman, S., & Nayeem, S. (2020). A Layered Framework for Virtual Guidance to Network Maintenance Based on Augmented Reality. IT Convergence and Security, 111-121. URL: https://doi.org/10.1007/978-981-15-9354-3_11"
39,Safe and Secure Multi-User Wearable AR Display Management Systems,"Wearable AR displays are expensive to purchase and, once they are tested and configured for AR experiences in the enterprise, they are highly valuable, limited resources. One of the issues AR managers encounter when seeking funding to purchase wearable AR displays is that no single user needs to have the display for all their tasks during a shift. In fact, until many more AR experiences are published and accepted, display devices are in use for only a fraction of a work day.

In principle, different workplace roles could use the same AR display during different parts of a process or a shift, thereby distributing the fixed cost of the hardware across multiple users and procedures, and ensuring that the system is not idle for significant time.

This research topic focuses on development of solutions to address two issues that currently prevent wearable AR displays from serving as multi-user resources. The first challenge is an environmental health and safety issue. Unless procedures for cleaning AR displays are tested and proven to the workforce to be effective and safe for them, employees are uncomfortable using a shared personal device. Sensitivity to this issue is even greater since the emergence of Covid-19.

The second issue that presents a barrier is the extension of mobile device management (MDM) to AR displays. There must be easy-to-use, reliable, effective and secure authentication of users who share wearable AR displays. User authentication, without typing in user names and passwords, is required in order that the user wearing the AR display at any time receive only those work orders and information that match the employee's current work order, level of training and roles on the job site.

The scope of this research straddles two fields that are not easily combined. The two topics could be studied separately.

","sanitation, clean equipment, access control, user authentication, authorization, biometric, safe display cleaning,, safety, sanitation, access control, data protection, security systems,  authentication, message authentication, authorization","Displays, End User and User Experience, Technology","Workplace safety managers and officers, IT security managers, employees working in facilities driven by work orders, AR managers, AR experience developers, AR interface designers who would develop prompts and procedures for easy login",#NAME?,"This project will require laboratory or bench studies with different sanitation systems, then microbiological studies to determine effectiveness of different procedures. For the authentication and log in systems, development of biometric identification systems would be valuable. These could be compared with commercial log-in interfaces to manage user identification. Further, after the tests in laboratories, there should be research on the use of these approaches with end users for acceptance.",Near,This topic is closely related to another proposed AREA Research Agenda topic on end user biometric authentication for security purposes [Tauthentication5-biometric]. The topics could be combined with other AR security topics to develop a full research program.,"In July 2021, https://cyberbytesfoundation.org/news/cyber-bytes-foundation-announces-grant-award/[NISTÃ¢ÂÂs Public Safety Communications Research Division has awarded a $1M grant to CyberBytes Foundation (CBF) and XR Saftey Initiative (XRSI)] to study feasibility and develop natural AR device user authentication methods that do not require users to perform specific actions (typing passwords, swiping ID cards). XRSI Privacy & Safety Framework will be used as a tool to assess natural AR Authentication methods by first responders and others working in public safety organizations.",Christine Perey,8/31/2021,4.19,"De S Ribeiro, M. G., Mazuecos, I. L., Marinho, F., & dos Santos, A. N. G. (2019). Agile Explorations in AR. IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society. URL: https://doi.org/10.1109/iecon.2019.8926838 | Thomas, D., & Holmquist, L. E. (2020). WristAR: A Wrist-Mounted Augmented Reality Interface. 19th International Conference on Mobile and Ubiquitous Multimedia. URL: https://doi.org/10.1145/3428361.3432077 | Speicher, M., Hall, B. D., Yu, A., Zhang, B., Zhang, H., Nebeling, J., & Nebeling, M. (2018). XD-AR. Proceedings of the ACM on Human-Computer Interaction, 2(EICS), 1-24. URL: https://doi.org/10.1145/3229089 | Knierim, P., Wo?niak, P. W., Abdelrahman, Y., & Schmidt, A. (2019). Exploring the Potential of Augmented Reality in Domestic Environments. Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services. URL: https://doi.org/10.1145/3338286.3340142 | Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018"
40,Barriers to Adoption of AR-assisted Inspection for Quality and Compliance,"Real world conditions must be compared with the agreed or defined compliance targets in many industries. In the future, any discrepancies detected through machine learning or artificial intelligence algorithms trained on compliant samples, could automatically show those discrepancies to the user in AR view.

Inspection use cases are not as widely implemented as step-by-step instruction delivery (task guidance) remote assistance and training. Companies with AR deployments in other use case categories could increase their ROI on AR investments if they were to expand their support for AR-assisted inspections. Providers of technologies need greater insights into inspection requirements and industries that perform inspections before work continues or, for compliance purposes, require inspections to be documented.

","inspection, quality, safety, compliance, policy, use cases, quality control, quality management, inspection, defects, fault detection, measurement, nondestructive examination, nondestructive testing, process monitoring, product quality, quality assurance, testing","Industries, Use Cases","Business and production managers in any industry where inspections are performed for review and confirmation of meeting any quality and/or safety policies, Safety managers, compliance managers, quality managers",#NAME?,"Interviews with business and production managers in any industry where inspections are performed for review and confirmation of meeting any quality and/or safety policies, safety managers, compliance managers, quality managers will need to be conducted and their KPIs documented.

In parallel, existing ML or AI techniques will need to be extended or new data sets for training created for use with AR technologies for capture and vision-based objective analysis of real world conditions. When real world conditions diverge from the compliance goal, any discrepancies will automatically be presented to the user in AR view. Following development of test methodologies, results will be validated by compliance specialists. End user acceptance and user experience will also be studied through feedback from users in interviews and surveys following use of the inspection use case in controlled environments.",Medium,This topic or theme of research overlap with the topic of using AR for automatically detecting workplace safety compliance. Automatic assessments of the workplace could also provide alerts when supplies are needed or maintenance scheduled. The same research topic could be combined with study of user interfaces and interaction paradigms for emergency response use cases.,This topic was submitted for 9th AREA research projects and received high support.,Christine Perey,8/31/2021,2.01,"Knierim, P., Wo?niak, P. W., Abdelrahman, Y., & Schmidt, A. (2019). Exploring the Potential of Augmented Reality in Domestic Environments. Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services. URL: https://doi.org/10.1145/3338286.3340142 | Alqahtani, H., & Kavakli, M. (2017). A theoretical model to measure user's behavioural intention to use iMAP-CampUS app. 2017 12th IEEE Conference on Industrial Electronics and Applications (ICIEA). URL: https://doi.org/10.1109/iciea.2017.8282928 | Babu, N. S. C. (2017). Keynote 1: Internet of Things(IoT) and augmented reality for e-learning. 2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH). URL: https://doi.org/10.1109/eleltech.2017.8074987 | Pringle, A., Hutka, S., Mom, J., van Esch, R., Heffernan, N., & Chen, P. (2019). Ethnographic study of a commercially available augmented reality HMD app for industry work instruction. Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments. URL: https://doi.org/10.1145/3316782.3322752 | Thomas, D., & Holmquist, L. E. (2020). WristAR: A Wrist-Mounted Augmented Reality Interface. 19th International Conference on Mobile and Ubiquitous Multimedia. URL: https://doi.org/10.1145/3428361.3432077"
41,"Visualization of Routes, Risks and Transit Time in AR","Efficient navigation between locations is a challenge encountered in many use cases. Routing and guidance to a location is a killer app for smartphones. Using context to help users navigate to their destinations will also be valuable for AR users but more research is needed to integrate real time data in route calculation and further study on user interfaces will also benefit this use case.

Traffic information from smart phone users contributes to calculations of routes for drivers. At a finer grain, real time data from captured video (e.g., on users and their devices) and stationary or mobile sensors could further improve route planning. Route planning could be made more efficient in workplaces and to remote locations. Visualizing routes and transit times in a wearable AR display permits the user to use both hands and avoids the user needing to look away from the objects and possible obstacles in the vicinity.

For example, in factories or warehouses, workers need to avoid moving through zones where robots are operating, where materials they are transporting do not fit through openings or through any space that is secure and requires credentials for entry/exit. Often the professional is expected to travel to a place which is unfamiliar/to which they have never been. Studies that train, with machine learning, algorithms to detect and use real world conditions would be highly beneficial. A professional may avoid unsafe or impassible routes.

","geospatial AR, GPS, global positioning system, location, position, orientation, route, route optimization, navigation, planning, guidance, routing, computerised navigation, global positioning system, navigation, navigation systems","Use Cases, End User and User Experience","Many use cases include the need for a user to walk or drive between locations. When conditions are apt to change between locations or the exact destination is new each time, an automatic, real-time and AR-enabled navigation support technology can ensure the most efficient and safest routes are followed. Visualization in AR removes the need to look at another device for route information. When small incremental improvements in efficiency are compounded over thousands of users, following optimized routes can impact workforce productivity and lower risk.",#NAME?,"Visualizing route, risk and transit time in AR requires use of geospatial positioning and orientation and will build upon existing navigation technologies and extending technologies already in use (e.g., smart phones) in a variety of environmental conditions (e.g., low and bright light). Indoor navigation technologies (without use of GPS) can build upon use of beacons and other types of landmarks that can be detected using an AR-enabled device. Extensive user testing with diverse user interfaces is required to develop options that meet the needs of different use cases.",Medium,"Visualization of routes, risks and transit time is a use case based on real time data and AI, and can be combined with studies of AR-enhanced use cases, such as situational awareness and simulation. It also can be combined with research into and contributions to the field of technology for error and risk detection.","This topic has been studied in many dimensions and in conjunction with other services. In 2015, https://www.researchgate.net/publication/272760699_Location-Based_Augmented_Reality_Information_for_Bus_Route_Planning_System[a study demonstrated that AR could help users of public transportation by putting destinations and other information on municipal buses].

In March 2021, Google https://www.theverge.com/2021/3/30/22357528/google-maps-directions-indoor-ar-live-view-fuel-efficient-weather-air-quality-layer[announced that it would provide live AR view of route and guidance] using Google Maps for pedestrians in airports, transit stations, and malls.",Christine Perey,8/31/2021,3.54,"Cervenak, R., & Masek, P. (2019). ARKit as indoor positioning system. 2019 11th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT). URL: https://doi.org/10.1109/icumt48472.2019.8970761 | Knierim, P., Wo?niak, P. W., Abdelrahman, Y., & Schmidt, A. (2019). Exploring the Potential of Augmented Reality in Domestic Environments. Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services. URL: https://doi.org/10.1145/3338286.3340142 | Zhao, Y., Tao, W., & Own, C.-M. (2019). The impression of virtual experience. Proceedings of the 16th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services. URL: https://doi.org/10.1145/3360774.3360811 | Marques, B., Carvalho, R., Dias, P., & Santos, B. S. (2019). Pervasive augmented reality for indoor uninterrupted experiences. Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers. URL: https://doi.org/10.1145/3341162.3343759 | Liu, B., & Meng, L. (2020). Doctoral Colloquium-Towards a Better User Interface of Augmented Reality Based Indoor Navigation Application. 2020 6th International Conference of the Immersive Learning Research Network (iLRN). URL: https://doi.org/10.23919/ilrn47897.2020.9155198"
42,Informing AR Users About Hazards in Proximity,"In many industries, workplaces contain a plethora of hazards. When known or anticipated, hazard management protocols reduce the risks associated with a user's encountering a hazard when performing tasks or fulfilling a work order. However, there are also hazards which, even if made aware of them, the user is untrained to treat or has insufficient time to avoid or deescalate. Alerts can provide the user time to react. On the other hand, there may be hazards that do not require any specific user actions.

Through data collected by user location sensing technologies on devices, and potentially on users' PPE, as well as maps of known hazards, data generated from sensors on stationary or moving machines, and other methods, artificial intelligence algorithms could be used to continuously maintain and monitor a dynamic 3D map of hazards in a user's proximity. The user may be provided the hazard proximity map at intervals or request to visualize hazards in proximity. When the user reaches conditions with respect to the hazard that suggests appropriate actions are needed, an alert on an AR device can spatially anchor the source of risk or hazard in the user's perception (see Automated Alert to Dangerous Settings [[ra-Salert5-dangerosity]]). If and when needed, guidance for risk mitigation can be provided.

","Hazard detection, hazard management protocol, hazard warning, location-detection, 3D spatial mapping, artificial intelligence, user interface, user experience, risk assessment, risk management, situational awareness, occupational risks, risk assessment, risk perception, accidents, occupational health, occupational safety, safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Industries, Technology, Business","Safety managers, workplace designers, risk managers",#NAME?,"This research can include studying appropriate definitions of proximity and risk in diverse industries and workplaces and/or using existing risk management tools, capturing data sets and training algorithms for types of hazards and testing reliability of AI in diverse conditions. The study of user interface and user experience for hazard notification systems will contribute to this field. Further, user studies will be required to measure cognitive load and user responsiveness to notifications of hazardous or potentially hazardous circumstances.",Near,"The scope of this research can span many industries and workplaces. It could be tailored to any industry in which AR is introduced and demonstrated with many workplace use cases. It is closely related to other proposed topic concerned with Automated Alert to Dangerous Settings, and a topic focusing on dangers due to chemical or radiation in employee vicinity. It could be combined with research on visualization of IoT data streams, 3D maps of known risk and other safety management programs. Further, it also can include or be an extension of numerous 3D user interface and user experience topics.","This peer-reviewed article published in December 2015 entitled https://www.sciencedirect.com/science/article/abs/pii/S092658051500196X[""Proximity hazard indicator for workers-on-foot near miss interactions with construction equipment and geo-referenced hazard areas""] pertains to the topic of this research.",Christine Perey,8/31/2021,1.83,"Aromaa, S., Väätänen, A., Kaasinen, E., Uimonen, M., & Siltanen, S. (2018). Human Factors and Ergonomics Evaluation of a Tablet Based Augmented Reality System in Maintenance Work. Proceedings of the 22nd International Academic Mindtrek Conference. URL: https://doi.org/10.1145/3275116.3275125 | Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | De S Ribeiro, M. G., Mazuecos, I. L., Marinho, F., & dos Santos, A. N. G. (2019). Agile Explorations in AR. IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society. URL: https://doi.org/10.1109/iecon.2019.8926838 | Schmidt, S., Steinicke, F., Irlitti, A., & Thomas, B. H. (2018). Floor-Projected Guidance Cues for Collaborative Exploration of Spatial Augmented Reality Setups. Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces. URL: https://doi.org/10.1145/3279778.3279806 | Miyazaki, M., & Komuro, T. (2018). Extended Workspace Using a Smartphone with a Depth Camera. 2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2018.00046"
43,Operational Risk Categorization/Matrices as an Indicator of AR Impact Potential,"While it is widely believed that the use of AR has vast potential in operational contexts, particularly those in which large amounts of risk are present, it is thus far difficult for senior stakeholders to narrow down operational processes and scenarios that stand to receive the largest benefit from the introduction of AR technology. Being able to clearly define and target specific opportunities for not only significant process improvement, but also tangible reductions in Lost Time Incident Rate (LTIR) and Total Recordable Incident Rate (TRIR), due to safe and effective operations.  It is quite standard in high-risk, high-compliance industries to operate under what is typically called a Risk Appetite Matrix, which considers risk type, projected impact, and projected likelihood to determine risk appetite and inform specific mitigation strategies. Because this determination is a human one and involves a series of factors, AR may even prove helpful around remote collaboration/guidance to operators as they make these decisions. Furthermore, the assignment of AR as PPE to particular workplace operations prone to higher risk should clearly demonstrate ROI that would warrant scalable and wide-spread adoption worldwide.

","Operational risk, operational risk management, Lost Time Incident Rate, LTIR, Total Recordable Incident Rate, TRIR, safety, compliance, hazard identification, occupational risks, risk assessment, risk perception, accidents, occupational health, occupational safety, safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Industries, Technology, Business","Business and production managers, operational excellence personnel, and HSE professionals in high-risk, high-compliance industries and/or industries where risk tolerance must be low (e.g. aviation and aerospace, healthcare, oil and gas, metals and mining, manufacturing, etc.). It may be helpful to consider individuals in a position to expose the organization to financial, safety, health, environmental, legal or regulatory, social, or reputational risk.","- As LTIR and TRIR are recorded and reported to OSHA each year (in US), it is essential to maintain these statistics so as to ensure a balanced scorecard.
- These metrics are carefully scrutinized at the C-Suite level and substantial budget is provided to help sustain/improve these metrics.
- Identification of operational contexts with the lowest risk appetite subsequently identifies specific opportunities for tangible outcomes that may be delivered via AR intervention.
- This, in turn, can result in tangible ROI and scalability that stimulates further investment in the use of AR, and potentially even AR as a PPE mandate, in some operational processes and contexts worldwide.","Utilize existing organizational and/or industry risk appetite matrix to identify operational processes for which intervention is most likely to impact organizational scorecard (medium to significant). If possible, target across multiple industries, focusing on one specific type of operational risk (financial, safety, health, environmental, legal or regulatory, social, or reputational). +
Decide upon an operational process/context for which pre-intervention metrics (LTIR, TRIR) data is available and introduce AR intervention via A/B trial scenario. Observe post-intervention data. +
Translate observable LTIR, TRIR decreases into Cost Benefit Analysis for AR implementation for different risk ratings of different types. +
Subsequent projects could adapt existing AI algorithms to scrape Standard Operating Procedures to identify recommended processes for AR supplementation. +",Near,"This study could link closely with existing research programs associated with remote operations support and decision-making, as well as any programs around business impact and measures. Additionally, it is a fantastic candidate for studies looking at the utilization of Artificial Intelligence/Machine Learning and AI.","References related to risk appetite matrices include:
https://www.good-governance.org.uk/services/risk-appetite-for-nhs-organisations-a-matrix-to-support-better-risk-sensitivity-in-decision-taking/ +
http://broadleaf.com.au/resource-material/risk-appetite-is-using-this-concept-worth-the-risk/ +
https://ppl.app.uq.edu.au/content/1.80.01-enterprise-risk-management +
https://www.ior-institute.org/wp-content/uploads/2018/11/20180905-Developing-and-Implementing-Effective-OpRisk-Appetite-Framework.pdf +
References related to HSE scorecard metrics include:
http://www.csb.gov/userfiles/file/mackenzie%20presentation.pdf +
https://bscdesigner.com/safety-kpis.htm +
https://www.levitt-safety.com/blog/trif-trir-and-dart-whats-the-difference-and-why-do-they-matter/#:~:text=TRIR%20stands%20for%20Total%20Recordable,effectiveness%20of%20safety%20programs%2C%20and +",Jennifer Rogers,8/31/2021,0.83,"Lutz, R. R. (2018). Safe-AR: Reducing Risk While Augmenting Reality. 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). URL: https://doi.org/10.1109/issre.2018.00018 | Ancient, C., & Teeuw, R. (2020). Augmented Reality Interface Design to Support Visualisation of ""Risk Landscapes."" Lecture Notes in Computer Science, 391-408. URL: https://doi.org/10.1007/978-3-030-49760-6_28 | Ko, H., Oksana, B., Na, I. S., & Pan, S. B. (2018). Analysis an identification with ECG base in augmented-reality. Proceedings of the 2018 Conference on Research in Adaptive and Convergent Systems. URL: https://doi.org/10.1145/3264746.3264802 | Aureliano Junior, M. J., Peixoto, I. A., Cyrino, G. F., Santos Peres, I. C. dos, Cardoso, A., Lamounier Junior, E. A., & Lima, G. F. de. (2018). Mobile Application to Support Interventions in Electric Power Substations with Augmented Reality Techniques and BIM. 2018 20th Symposium on Virtual and Augmented Reality (SVR). URL: https://doi.org/10.1109/svr.2018.00007 | Aromaa, S., Väätänen, A., Aaltonen, I., Goriachev, V., Helin, K., & Karjalainen, J. (2020). Awareness of the real-world environment when using augmented reality head-mounted display. Applied Ergonomics, 88, 103145. URL: https://doi.org/10.1016/j.apergo.2020.103145"
44,Minimum Useful Fidelity of Streamed Large-scale 3D Models over 5G,"Large scale 3D models and point clouds play an important role in many fields ranging from simulation to Product Lifecycle Management to digital twins deployed on a plethora of AR-capable devices. However, due to systems or resource limitations, these models are not always as close to the reality as they purport to be.

Using AR connected to 5G networks, it is possible to stream these models to a device to assist processes performed by human operators or technicians. Generally speaking, the simpler the model (i.e. the lower the fidelity), the less resource is required for streaming. However, if simplification goes too far, utility suffers, possibly preventing the operator from performing the intended task.

The research scope should include comparative studies measuring the exact impact of automatic model and point cloud simplification due to streaming, possibly expressed by the decrease in polygon count vs the time required and error rates achieved in a particular operations. Measurement methods would be developed to ensure accuracy within 5% margin of error.

","point cloud, large-scale 3D models, polygons, low-poly, high-poly, realistic, surfaces, finite element method, computer simulation, digital simulation, computational mechanics, computer aided engineering, discrete event simulation, virtualization","Technology, Business","Operations leaders, financial management, OEM manufacturers, Independent Software Vendors, Cloud Service Providers",#NAME?,This research project will make a statistically significant number of comparisons between versions of different fidelity of the same large-scale 3D model and point clouds and will examine their impact on the performance aided by said models. Examining the relationship between model fidelity and human performance will inform the investment process for large-scale 3D models. New methods could be developed to compare usefulness at different levels of fidelity in various industries to clarify why some industries require different levels of fidelity to meet their objectives.,Medium,This research topic can be combined with other projects examining the tradeoffs between fidelity and function of large-scale 3D models.,Several AREA members are already working in this field and the 7th AREA research project performed a comparison of commercial solutions available for model decimation although did not study the streaming aspect of this research topic. The MxD is interested in collaborating to use its mmWave 5G infrastructure in a factory setting to study this topic further.,Peter Orban,8/31/2021,1.12,"Fradi, A., Louhichi, B., Mahjoub, M. A., & Eynard, B. (2017). 3D Object Retrieval Based on Similarity Calculation in 3D Computer Aided Design Systems. 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications (AICCSA). URL: https://doi.org/10.1109/aiccsa.2017.101 | Xue, Y., Xu, S., Wang, L., Dai, C., & Wu, Y. (2019). Dual-Model Approach for Engineering Collision Detection in the CAVE Environment. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00-24 | Hayashida, H., Funashima, H., Katayama-Yoshida, H., & Nomakuchi, T. (2017). Opening the Door for the New Methodology for Optimizing Functional Material Development in Technology Management Framework II. 2017 Portland International Conference on Management of Engineering and Technology (PICMET). URL: https://doi.org/10.23919/picmet.2017.8125242 | Large-Scale 3D Point Cloud Processing for Mixed and Augmented Reality. (2018). 2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2018.00018 | Wang, W., Ceylan, D., Mech, R., & Neumann, U. (2019). 3DN: 3D Deformation Network. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). URL: https://doi.org/10.1109/cvpr.2019.00113"
45,Rapid QA of Forensics and Public Safety 3D Scanning Outputs,"Accurately capturing accident, crime or crash scenes, and other scenes relevant from a Public Safety standpoint is of utmost importance for law enforcement or other government agencies. This tedious and error-prone work has tremendously benefitted from the adoption of laser scanners made by OEMs like Faro, Leica and others.

Deploying laser scanners to capture crime scenes and other relevant real world situations generates a complex point clouds which requires extensive post processing before the final models are constructed Ã¢ÂÂ a process that takes place offsite after scanning. Therefore, potential errors of over or under scanning - which can significantly deteriorate the quality of the model Ã¢ÂÂ is difficult to detect on location. This is of particular concern when the use of scanning equipment is not frequent, e.g. a small town police department or large-scale disaster event.

By deploying AR glasses it is possible to track the location of the scanning device and combine it with its effective scanning range at every stage to create a visual representation of the scanning footprint. This could yield an effective Ã¢ÂÂcoverage mapÃ¢ÂÂ visible via smart glasses that would help the operator spot under-scanned areas. This topic includes a detailed examination of scanning footprint detected via smart glasses, in comparison to the 3D scene captured by the actual point cloud.

","point cloud, laser scanning, disaster scene, crime scene, law enforcement, 3d models, point clouds, digital twin","Technology, Business","Public safety agencies such as police crime scene investigators, law enforcement, FEMA, OEM manufacturers. If techniques are widely published, Independent Software Vendors could integrate the capability as a new feature in their existing applications and support more devices.",#NAME?,This research project will make a statistically-significant number of comparisons between point clouds and their respective scanner location tracking information of the same site with the purpose of creating a regression model that accounts for measurement errors in the independent variables.,Medium,This research topic can be combined with other projects examining the tradeoffs between fidelity and function of large-scale 3D models.,There's an ISMAR 2019 paper about how to use AR device to track the viewpoint of the scanner to ensure that an object is fully scanned in 3D. This research topic could be an extension to the prior published research.,Peter Orban,8/31/2021,0.51,"Wei, Y., Zhang, T., Gu, K., & Shi, Z. (2017). Robust parameter estimation from point cloud data with noises for augmented reality. 2017 36th Chinese Control Conference (CCC). URL: https://doi.org/10.23919/chicc.2017.8028185 | Large-Scale 3D Point Cloud Processing for Mixed and Augmented Reality. (2018). 2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2018.00018 | Li, D., Zhang, H., Song, Z., Man, D., & Jones, M. W. (2017). An automatic laser scanning system for accurate 3D reconstruction of indoor scenes. 2017 IEEE International Conference on Information and Automation (ICIA). URL: https://doi.org/10.1109/icinfa.2017.8079017 | Fakour Sevom, V., Schwarz, S., & Gabbouj, M. (2018). Geometry-Guided 3D Data Interpolation for Projection-Based Dynamic Point Cloud Coding. 2018 7th European Workshop on Visual Information Processing (EUVIP). URL: https://doi.org/10.1109/euvip.2018.8611760 | De Oliveira Rente, P., Brites, C., Ascenso, J., & Pereira, F. (2019). Graph-Based Static 3D Point Clouds Geometry Coding. IEEE Transactions on Multimedia, 21(2), 284-299. URL: https://doi.org/10.1109/tmm.2018.2859591"
46,Multi-layered Approach to Public Asset Utilization in Smart Cities,"There is a wide range of assets in urban environments: public spaces, buildings, concentrations of demography, utilities, history, movement of people and objects and so on. These assets carry significant value for all those interacting with them but the nature and manifestation of the value depends on the context and the use case.

The nature of value associated with the same asset depends on the nature of the interaction: occupancy for a realtor, history for a tourist, compliance for the Code Enforcement employee and so on Ã¢ÂÂ all built around the same digital twin of the host city.

Following proper authorization, head mounted displays or handheld devices can unlock the value contained in an asset, guiding and enhancing the interactions of a user with a city and its inhabitants.

This research topic also includes architecting a multipurpose Digital Twin of a set of assets, associating them with various layers of value and examining modalities of consumption from a human factors perspective.

","public asset management, public services, scanning, smart cities, urbanization, intelligent buildings, urban growth, town and country planning, urban planning, digital twin, smart cities, street lighting","Technology, Business","Elected and professional urban leaders: Mayors, CIOs and CISOs of urban infrastructure, Independent Software Vendors, geospatial infrastructure providers, points of interest publishers","- According to the UN, 68% of the world population projected to live in urban areas by 2050. This will put an increased strain on most public assets to optimizing how to unlock their value will be critical for resident quality of life and visitor experiences.
- Best practices developed in urban design, information architecture and human factors will be extended by the results of this research.",This research will require scanning and associating data with urban assets and developing methodologies to test different use cases and scenarios. User satisfaction and productivity studies in field trials will contribute to development of best practices for specific industries.,Long,This topic is a good fit with most topics focused on Smart Cities and long-range outdoor positioning.,"The UN has published https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html#:~:text=News-,68%25%20of%20the%20world%20population%20projected%20to%20live%20in,areas%20by%202050%2C%20says%20UN&text=Today%2C%2055%25%20of%20the%20world's,increase%20to%2068%25%20by%202050[reports about urbanization and the challenges it raises for those managing urban data].",Peter Orban,8/31/2021,0.22,"Chen, K., Gonsalves, K., Guaralda, M., Turkay, S., & Kerr, J. (2019). Towards a Typology for Playable Digital Interventions in Urban Public. 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). URL: https://doi.org/10.1109/ismar-adjunct.2019.00123 | Innocent, T. (2018). Play about Place. Proceedings of the 4th Media Architecture Biennale Conference. URL: https://doi.org/10.1145/3284389.3284493 | Lee, L.-H. (2020). Invited Talk: Emerging Role of Digital Assistant in Augmented Reality Driven Human-City Interaction. 2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops). URL: https://doi.org/10.1109/percomworkshops48775.2020.9156243 | Nijholt, A. (2017). Humans as Avatars in Smart and Playable Cities. 2017 International Conference on Cyberworlds (CW). URL: https://doi.org/10.1109/cw.2017.23 | Zhang, L., Chen, S., Dong, H., & El Saddik, A. (2018). Visualizing Toronto City Data with HoloLens: Using Augmented Reality for a City Model. IEEE Consumer Electronics Magazine, 7(3), 73-80. URL: https://doi.org/10.1109/mce.2018.2797658"
